{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import string \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Naive Bayes and TF-IDF Vectorization \n",
    "\n",
    "In Classification tasks where we use a probabilistic model, we want to compute the probability of a all class given the observations, denoted as $P(Y=y|X)$, where $X$ is a vector consisting of $n$ independent variables, and $Y$ is the dependent variable, or the classification target. From the equation $P(Y=y|X)$, using Bayes Theorem, we can convert this equation to $\\frac{P(Y)P(X|Y)}{P(X)}$. Solving this equation for each $Y$ would give us a probability for each class, and to obtain a prediction for the given $X$, we would take the $\\arg\\max_{P(y|X)}$ as the predicted class. <br><br>\n",
    "\n",
    "Solving this equation $\\frac{P(Y)P(X|Y)}{P(X)}$ is however non-trivial. This is because $X$ is a vector of $n$ elements and this makes $P(X|Y)$ difficult to calculate. In Naive Bayes, an assumption is made that all $x_{i}$ are independent of each other. Thus, this equation can be converted to $\\frac{P(Y)P(x_{1}|Y)P(x_{2}|Y)....P(x_{n}|Y)}{P(X)}$. Since $P(X)$ is the same for a given value of $X$, the equation be simplified to $P(Y=y|X) = {P(Y) P(x_{1}|Y) P(x_{2}|Y) .... P(x_{n}|Y)}$. Without the independence assumption, $P(X|Y)$ would be equals to $P(x_{1}|Y) P(x_{2}|Y\\cap x_{1}) .... P(x_{n}| Y \\cap x_{1} \\cap... \\cap x_{n-1})$, which would be difficult to calculate<br><br>\n",
    "\n",
    "Prior = $P(Y)$ <br>\n",
    "Posterior = $P(Y|X)$ <br>\n",
    "Likelihood = $P(X|Y)$ <br><br>\n",
    "\n",
    "In the context of suggestion mining, where we use TF-IDF vectorizor to vectorize the text data, $Y = \\{0, 1\\}$, where $1$ represents a positive prediction that the text has a suggestion, and $0$ is a negative prediction. $X$ would be the data generated from the TF-IDF vectorizor. For TF-IDF vectorizors, we can fit each column of data to a normal distribution, and use that value to estimate the probability for any given $P(x_{i})$.(Gaussian Naive Bayes)\n",
    "\n",
    "## TF-IDF\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, and is a simple extension to the simple Bag of Words text vectorization method. This is the product of 2 terms, the Term Frequency (TF) and Inverse Document Frequency (IDF) <br>\n",
    "\n",
    "$TF(t,d) = f(t, d)$  <br>\n",
    "$IDF(t, D) =log\\frac{N}{|d \\in D: t \\in d|}$ <br>\n",
    "\n",
    "In other words, TF is the simply the count of number of times the word appeares within a particular document. IDF is the logarithm of the number of documents $N$ in the entire corpus, divided by the number of documents the term $t$ appears in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Data/App_Training.csv')\n",
    "test_data = pd.read_csv('./Data/App_Test_Labeled.csv')\n",
    "eval_data = pd.read_csv('./Data/SubtaskA_EvaluationData_labeled.csv', header = None, encoding = 'latin1')\n",
    "eval_data.columns = ['id', 'sentence', 'label']\n",
    "\n",
    "train_data.drop(labels = ['0'], axis = 1, inplace = True)\n",
    "test_data.drop(labels = ['0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663_3</td>\n",
       "      <td>Please enable removing language code from the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663_4</td>\n",
       "      <td>Note in your csproj file there is a Supported...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664_1</td>\n",
       "      <td>Wich means the new version not fully replaced...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664_2</td>\n",
       "      <td>Some of my users will still receive the old x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664_3</td>\n",
       "      <td>The store randomly gives the old xap or the n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           sentence  label\n",
       "0  663_3   Please enable removing language code from the...      1\n",
       "1  663_4   Note in your csproj file there is a Supported...      0\n",
       "2  664_1   Wich means the new version not fully replaced...      0\n",
       "3  664_2   Some of my users will still receive the old x...      0\n",
       "4  664_3   The store randomly gives the old xap or the n...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1310_1</td>\n",
       "      <td>I am not asking Microsoft to Gives permission ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1312_1</td>\n",
       "      <td>somewhere between Android and iPhone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1313_1</td>\n",
       "      <td>And in the Windows Store you can flag the App ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1313_2</td>\n",
       "      <td>Many thanks Sameh Hi As we know there is a lot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1313_3</td>\n",
       "      <td>The idea is that we can develop a regular app ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           sentence  label\n",
       "0  1310_1  I am not asking Microsoft to Gives permission ...      1\n",
       "1  1312_1              somewhere between Android and iPhone       0\n",
       "2  1313_1  And in the Windows Store you can flag the App ...      0\n",
       "3  1313_2  Many thanks Sameh Hi As we know there is a lot...      0\n",
       "4  1313_3  The idea is that we can develop a regular app ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9566</td>\n",
       "      <td>This would enable live traffic aware apps.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9569</td>\n",
       "      <td>Please try other formatting like bold italics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9576</td>\n",
       "      <td>Since computers were invented to save time I s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9577</td>\n",
       "      <td>Allow rearranging if the user wants to change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9579</td>\n",
       "      <td>Add SIMD instructions for better use of ARM NE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           sentence  label\n",
       "0  9566         This would enable live traffic aware apps.      0\n",
       "1  9569  Please try other formatting like bold italics ...      1\n",
       "2  9576  Since computers were invented to save time I s...      1\n",
       "3  9577  Allow rearranging if the user wants to change ...      1\n",
       "4  9579  Add SIMD instructions for better use of ARM NE...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())\n",
    "display(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sentence'] = train_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
    "test_data['sentence'] = test_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
    "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
    "\n",
    "train_data['sentence'] = train_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "test_data['sentence'] = test_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663_3</td>\n",
       "      <td>please enable removing language code from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663_4</td>\n",
       "      <td>note in your csproj file there is a supportedc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664_1</td>\n",
       "      <td>wich means the new version not fully replaced ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664_2</td>\n",
       "      <td>some of my users will still receive the old xa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664_3</td>\n",
       "      <td>the store randomly gives the old xap or the ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           sentence  label\n",
       "0  663_3  please enable removing language code from the ...      1\n",
       "1  663_4  note in your csproj file there is a supportedc...      0\n",
       "2  664_1  wich means the new version not fully replaced ...      0\n",
       "3  664_2  some of my users will still receive the old xa...      0\n",
       "4  664_3  the store randomly gives the old xap or the ne...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1310_1</td>\n",
       "      <td>i am not asking microsoft to gives permission ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1312_1</td>\n",
       "      <td>somewhere between android and iphone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1313_1</td>\n",
       "      <td>and in the windows store you can flag the app ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1313_2</td>\n",
       "      <td>many thanks sameh hi as we know there is a lot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1313_3</td>\n",
       "      <td>the idea is that we can develop a regular app ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           sentence  label\n",
       "0  1310_1  i am not asking microsoft to gives permission ...      1\n",
       "1  1312_1               somewhere between android and iphone      0\n",
       "2  1313_1  and in the windows store you can flag the app ...      0\n",
       "3  1313_2  many thanks sameh hi as we know there is a lot...      0\n",
       "4  1313_3  the idea is that we can develop a regular app ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9566</td>\n",
       "      <td>this would enable live traffic aware apps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9569</td>\n",
       "      <td>please try other formatting like bold italics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9576</td>\n",
       "      <td>since computers were invented to save time i s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9577</td>\n",
       "      <td>allow rearranging if the user wants to change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9579</td>\n",
       "      <td>add simd instructions for better use of arm ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           sentence  label\n",
       "0  9566          this would enable live traffic aware apps      0\n",
       "1  9569  please try other formatting like bold italics ...      1\n",
       "2  9576  since computers were invented to save time i s...      1\n",
       "3  9577  allow rearranging if the user wants to change ...      1\n",
       "4  9579  add simd instructions for better use of arm ne...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())\n",
    "display(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.754706\n",
      "1    0.245294\n",
      "Name: label, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind = 'bar')\n",
    "print(train_data['label'].value_counts()/len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6415\n",
       "1    2085\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbility</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcd</th>\n",
       "      <th>abi</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>...</th>\n",
       "      <th>zindex</th>\n",
       "      <th>ziner</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zoomlevel</th>\n",
       "      <th>zune</th>\n",
       "      <th>zunes</th>\n",
       "      <th>ıts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  ab  abandon  abandoned  abbility  abc  abcd  abi  abilities  ability  \\\n",
       "0    0   0        0          0         0    0     0    0          0        0   \n",
       "1    0   0        0          0         0    0     0    0          0        0   \n",
       "2    0   0        0          0         0    0     0    0          0        0   \n",
       "3    0   0        0          0         0    0     0    0          0        0   \n",
       "4    0   0        0          0         0    0     0    0          0        0   \n",
       "\n",
       "   ...  zindex  ziner  zip  zipping  zoom  zooming  zoomlevel  zune  zunes  \\\n",
       "0  ...       0      0    0        0     0        0          0     0      0   \n",
       "1  ...       0      0    0        0     0        0          0     0      0   \n",
       "2  ...       0      0    0        0     0        0          0     0      0   \n",
       "3  ...       0      0    0        0     0        0          0     0      0   \n",
       "4  ...       0      0    0        0     0        0          0     0      0   \n",
       "\n",
       "   ıts  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  \n",
       "\n",
       "[5 rows x 8498 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_matrix = count_vectorizer.fit_transform(train_data['sentence']).toarray()\n",
    "count_df = pd.DataFrame(count_matrix, columns = count_vectorizer.get_feature_names_out ())\n",
    "count_df['label'] = train_data['label']\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c53eed83d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot top 25 words for positive\n",
    "pos_count_df = count_df[count_df['label'] == 1].copy()\n",
    "pos_count_df.drop(['label'],axis = 1, inplace = True)\n",
    "top_25_words = pos_count_df.sum().sort_values(ascending = False).iloc[0:25]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Top 25 words of positive class\")\n",
    "sns.barplot(x = top_25_words.index, y = top_25_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c56940f520>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot top 25 words for negative\n",
    "neg_count_df = count_df[count_df['label'] == 0].copy()\n",
    "neg_count_df.drop(['label'],axis = 1, inplace = True)\n",
    "top_25_words = neg_count_df.sum().sort_values(ascending = False).iloc[0:25]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Top 25 words of negative class\")\n",
    "sns.barplot(x = top_25_words.index, y = top_25_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observation, most of the top few words appear in both negative and positive classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa compliant</th>\n",
       "      <th>ab reset</th>\n",
       "      <th>abandon market</th>\n",
       "      <th>abandon previous</th>\n",
       "      <th>abandoned like</th>\n",
       "      <th>abbility copy</th>\n",
       "      <th>abc sings</th>\n",
       "      <th>abcd ends</th>\n",
       "      <th>abi avoid</th>\n",
       "      <th>abi generating</th>\n",
       "      <th>...</th>\n",
       "      <th>zune property</th>\n",
       "      <th>zune ridiculous</th>\n",
       "      <th>zune software</th>\n",
       "      <th>zune sort</th>\n",
       "      <th>zune tile</th>\n",
       "      <th>zune timefull</th>\n",
       "      <th>zune wireless</th>\n",
       "      <th>zunes audible</th>\n",
       "      <th>ıts gona</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa compliant  ab reset  abandon market  abandon previous  abandoned like  \\\n",
       "0              0         0               0                 0               0   \n",
       "1              0         0               0                 0               0   \n",
       "2              0         0               0                 0               0   \n",
       "3              0         0               0                 0               0   \n",
       "4              0         0               0                 0               0   \n",
       "\n",
       "   abbility copy  abc sings  abcd ends  abi avoid  abi generating  ...  \\\n",
       "0              0          0          0          0               0  ...   \n",
       "1              0          0          0          0               0  ...   \n",
       "2              0          0          0          0               0  ...   \n",
       "3              0          0          0          0               0  ...   \n",
       "4              0          0          0          0               0  ...   \n",
       "\n",
       "   zune property  zune ridiculous  zune software  zune sort  zune tile  \\\n",
       "0              0                0              0          0          0   \n",
       "1              0                0              0          0          0   \n",
       "2              0                0              0          0          0   \n",
       "3              0                0              0          0          0   \n",
       "4              0                0              0          0          0   \n",
       "\n",
       "   zune timefull  zune wireless  zunes audible  ıts gona  label  \n",
       "0              0              0              0         0      1  \n",
       "1              0              0              0         0      0  \n",
       "2              0              0              0         0      0  \n",
       "3              0              0              0         0      0  \n",
       "4              0              0              0         0      0  \n",
       "\n",
       "[5 rows x 47173 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot but with bi-grams instead\n",
    "count_vectorizer = CountVectorizer(ngram_range = (2,2))\n",
    "count_matrix = count_vectorizer.fit_transform(train_data['sentence']).toarray()\n",
    "count_df = pd.DataFrame(count_matrix, columns = count_vectorizer.get_feature_names_out ())\n",
    "count_df['label'] = train_data['label']\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-16d42d94d174>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_count_df.drop(['label'],axis = 1, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa7f5ec7c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot top 10 bi-grams for positive\n",
    "pos_count_df = count_df[count_df['label'] == 1]\n",
    "pos_count_df.drop(['label'],axis = 1, inplace = True)\n",
    "top_10_words = pos_count_df.sum().sort_values(ascending = False).iloc[0:10]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Top 10 bi-grams of positive class\")\n",
    "sns.barplot(x = top_10_words.index, y = top_10_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-1792d2f00ab9>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_count_df.drop(['label'],axis = 1, inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fa252cb9d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot top 10 bi-gram for negative\n",
    "neg_count_df = count_df[count_df['label'] == 0]\n",
    "neg_count_df.drop(['label'],axis = 1, inplace = True)\n",
    "top_10_words = neg_count_df.sum().sort_values(ascending = False).iloc[0:10]\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Top 10 bi-grams of negative class\")\n",
    "sns.barplot(x = top_10_words.index, y = top_10_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr Params: max_df = 0.85 min_df = 0.01\n",
      "Curr Params: max_df = 0.85 min_df = 0.02\n",
      "Curr Params: max_df = 0.85 min_df = 0.03\n",
      "Curr Params: max_df = 0.9 min_df = 0.01\n",
      "Curr Params: max_df = 0.9 min_df = 0.02\n",
      "Curr Params: max_df = 0.9 min_df = 0.03\n",
      "Curr Params: max_df = 0.95 min_df = 0.01\n",
      "Curr Params: max_df = 0.95 min_df = 0.02\n",
      "Curr Params: max_df = 0.95 min_df = 0.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Do grid search \n",
    "kf = KFold(n_splits = 5)\n",
    "X = train_data['sentence']\n",
    "Y = train_data['label']\n",
    "max_df_ranges = [0.85, 0.9, 0.95] \n",
    "min_df_ranges = [0.01, 0.02, 0.03]\n",
    "\n",
    "best_params = {}\n",
    "best_results = {} \n",
    "curr_best_f1 = float('-inf')\n",
    "\n",
    "for max_df in max_df_ranges:\n",
    "    for min_df in min_df_ranges:\n",
    "        f1_scores = []\n",
    "        recall_scores = []\n",
    "        accuracy_scores = []\n",
    "        precision_scores = []\n",
    "        print(f\"Curr Params: max_df = {max_df} min_df = {min_df}\")\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "            tfidf_vectorizer = TfidfVectorizer(max_df = max_df, min_df = min_df, ngram_range = (1,2))\n",
    "            tfidf_vectorizer.fit(X_train)\n",
    "            X_train_vectorized = tfidf_vectorizer.transform(X_train)\n",
    "            X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "            clf = GaussianNB()\n",
    "            clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "            Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "        \n",
    "            f1_scores.append(f1_score(Y_test, Y_pred))\n",
    "            recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "            precision_scores.append(precision_score(Y_test, Y_pred))\n",
    "            accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "            \n",
    "            mean_f1 = sum(f1_scores)/5\n",
    "            if mean_f1 > curr_best_f1:\n",
    "                curr_best_f1 = mean_f1\n",
    "                best_params['max_df'] = max_df\n",
    "                best_params['min_df'] = min_df\n",
    "                best_results['f1'] = sum(f1_scores)/5\n",
    "                best_results['precision'] = sum(precision_scores)/5\n",
    "                best_results['recall'] = sum(recall_scores)/5\n",
    "                best_results['accuracy'] = sum(accuracy_scores)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.5517392837153243,\n",
       " 'precision': 0.45120650612465096,\n",
       " 'recall': 0.7792463079497491,\n",
       " 'accuracy': 0.736}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_df': 0.85, 'min_df': 0.03}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = best_params['max_df'], min_df = best_params['min_df'], ngram_range = (1,2))\n",
    "\n",
    "X_train = train_data['sentence']\n",
    "Y_train = train_data['label']\n",
    "\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "clf.fit(X_train_vectorized.toarray(), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.4011627906976744\n",
      "Recall Score: 0.7931034482758621\n",
      "Precision Score: 0.26848249027237353\n",
      "Accuracy Score: 0.7527010804321729\n"
     ]
    }
   ],
   "source": [
    "X_test = eval_data['sentence']\n",
    "Y_test = eval_data['label']\n",
    "\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision Score: {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558 188 18 69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[558, 188],\n",
       "       [ 18,  69]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "display(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr Params: max_df = 0.85 min_df = 0.01\n",
      "Curr Params: max_df = 0.85 min_df = 0.02\n",
      "Curr Params: max_df = 0.85 min_df = 0.03\n",
      "Curr Params: max_df = 0.9 min_df = 0.01\n",
      "Curr Params: max_df = 0.9 min_df = 0.02\n",
      "Curr Params: max_df = 0.9 min_df = 0.03\n",
      "Curr Params: max_df = 0.95 min_df = 0.01\n",
      "Curr Params: max_df = 0.95 min_df = 0.02\n",
      "Curr Params: max_df = 0.95 min_df = 0.03\n"
     ]
    }
   ],
   "source": [
    "#Do grid search \n",
    "kf = KFold(n_splits = 5)\n",
    "X = train_data['sentence']\n",
    "Y = train_data['label']\n",
    "max_df_ranges = [0.85, 0.9, 0.95] \n",
    "min_df_ranges = [0.01, 0.02, 0.03]\n",
    "\n",
    "best_params = {}\n",
    "best_results = {} \n",
    "curr_best_f1 = float('-inf')\n",
    "\n",
    "for max_df in max_df_ranges:\n",
    "    for min_df in min_df_ranges:\n",
    "        f1_scores = []\n",
    "        recall_scores = []\n",
    "        accuracy_scores = []\n",
    "        precision_scores = []\n",
    "        print(f\"Curr Params: max_df = {max_df} min_df = {min_df}\")\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "            tfidf_vectorizer = CountVectorizer(max_df = max_df, min_df = min_df, ngram_range = (1,2))\n",
    "            tfidf_vectorizer.fit(X_train)\n",
    "            X_train_vectorized = tfidf_vectorizer.transform(X_train)\n",
    "            X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "            clf = MultinomialNB()\n",
    "            clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "            Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "        \n",
    "            f1_scores.append(f1_score(Y_test, Y_pred))\n",
    "            recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "            precision_scores.append(precision_score(Y_test, Y_pred))\n",
    "            accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "            \n",
    "            mean_f1 = sum(f1_scores)/5\n",
    "            if mean_f1 > curr_best_f1:\n",
    "                curr_best_f1 = mean_f1\n",
    "                best_params['max_df'] = max_df\n",
    "                best_params['min_df'] = min_df\n",
    "                best_results['f1'] = sum(f1_scores)/5\n",
    "                best_results['precision'] = sum(precision_scores)/5\n",
    "                best_results['recall'] = sum(recall_scores)/5\n",
    "                best_results['accuracy'] = sum(accuracy_scores)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.633615973416623,\n",
       " 'precision': 0.6482982702352655,\n",
       " 'recall': 0.6423444814614505,\n",
       " 'accuracy': 0.8355294117647059}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_df': 0.85, 'min_df': 0.01}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "tfidf_vectorizer = CountVectorizer(max_df = best_params['max_df'], min_df = best_params['min_df'], ngram_range = (1,2))\n",
    "\n",
    "X_train = train_data['sentence']\n",
    "Y_train = train_data['label']\n",
    "\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "clf.fit(X_train_vectorized.toarray(), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5714285714285715\n",
      "Recall Score: 0.6206896551724138\n",
      "Precision Score: 0.5294117647058824\n",
      "Accuracy Score: 0.9027611044417767\n"
     ]
    }
   ],
   "source": [
    "X_test = eval_data['sentence']\n",
    "Y_test = eval_data['label']\n",
    "\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision Score: {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698 48 33 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[698,  48],\n",
       "       [ 33,  54]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "display(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of SVM\n",
    "\n",
    "Support Vector Machines are an extension of Support Vector Classifiers, which are in turn an extension of Maximal margin classifiers. Maximal Margin Classifiers are a linear classifier for linearly separable classification problems. <br> \n",
    "\n",
    "In a Maximal Margin Classifier, we find a hyperplane/line (depending) on the dimension that can separate all the observations within the dataset into its respective classes. However, there can be an infinite number of such hyperplanes. Thus, the goal of the MMC is to maximise the margin, which is defined as the shortest distance between a point and the hyperplane. This becomes an optimization problem with the following objective function and constraints: <br>\n",
    "1. $Maximize M$ = $\\frac{1}{\\sum\\beta_{i}}$\n",
    "2. Subject to $\\sum\\beta_{i} = 1$ - Number of independent Variables \n",
    "3. and $y_{i}(\\beta_{0} + \\beta_{1}X_{i1} + ... + \\beta_{p}X_{ip}) \\geq 1$ <br>\n",
    "\n",
    "However, the problem with a MMC is that we are unable to handle cases where the data samples are linearly inseparable, and in the MMC is also highly sensitive to outliers. To handle misclassifications, we introduce a slack variable $C$, that allows the observations to violate the margins. The optimization then becomes: <br>\n",
    "\n",
    "1. $Maximize M$ = $\\frac{1}{\\sum\\beta_{i}}$\n",
    "2. Subject to $\\sum\\beta_{i} = 1$ - Number of independent Variables \n",
    "3. and $y_{i}(\\beta_{0} + \\beta_{1}X_{i1} + ... + \\beta_{p}X_{ip}) \\geq (1 - e)$ <br>\n",
    "4. and $\\sum e_{i} \\leq C$ \n",
    "5. where $e_{i} \\geq 0$\n",
    "\n",
    "If $e_{i} = 0$, the ith observation is on the correct side of the margin <br>\n",
    "If $e_{i} \\gt 0$, the ith observation is on the wrong side of the margin <br>\n",
    "If $e_{i} \\gt 1$, the ith observation is on the wrong side of the hyperplane <br>\n",
    "In this case, C is a hyperparameter that can be tuned using cross validation, and it measures the amount of violations of the margin. With a larger C, it allows for more slack, which creates a stronger regularization effect. However. This model is still a linear model with a linear decision boundary. <br>\n",
    "\n",
    "In order to create a non-linear decision boundary, we need to project the data samples into a higher dimension, then solve the same optimization problem. SVM uses the kernel trick, which represents the datapoints by their pairwise distances. A kernel function is a function that returns a modified dot product. This reduces the time complexity and computational cost required to do the transformation. This allows SVM to create a non-linear decision boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Data/App_Training.csv')\n",
    "test_data = pd.read_csv('./Data/App_Test_Labeled.csv')\n",
    "eval_data = pd.read_csv('./Data/SubtaskA_EvaluationData_labeled.csv', header = None, encoding = 'latin1')\n",
    "eval_data.columns = ['id', 'sentence', 'label']\n",
    "\n",
    "train_data.drop(labels = ['0'], axis = 1, inplace = True)\n",
    "test_data.drop(labels = ['0'], axis = 1, inplace = True)\n",
    "\n",
    "train_data['sentence'] = train_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
    "test_data['sentence'] = test_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
    "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
    "\n",
    "train_data['sentence'] = train_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "test_data['sentence'] = test_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>663_3</td>\n",
       "      <td>please enable removing language code from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663_4</td>\n",
       "      <td>note in your csproj file there is a supportedc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>664_1</td>\n",
       "      <td>wich means the new version not fully replaced ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664_2</td>\n",
       "      <td>some of my users will still receive the old xa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>664_3</td>\n",
       "      <td>the store randomly gives the old xap or the ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           sentence  label\n",
       "0  663_3  please enable removing language code from the ...      1\n",
       "1  663_4  note in your csproj file there is a supportedc...      0\n",
       "2  664_1  wich means the new version not fully replaced ...      0\n",
       "3  664_2  some of my users will still receive the old xa...      0\n",
       "4  664_3  the store randomly gives the old xap or the ne...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1310_1</td>\n",
       "      <td>i am not asking microsoft to gives permission ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1312_1</td>\n",
       "      <td>somewhere between android and iphone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1313_1</td>\n",
       "      <td>and in the windows store you can flag the app ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1313_2</td>\n",
       "      <td>many thanks sameh hi as we know there is a lot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1313_3</td>\n",
       "      <td>the idea is that we can develop a regular app ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           sentence  label\n",
       "0  1310_1  i am not asking microsoft to gives permission ...      1\n",
       "1  1312_1               somewhere between android and iphone      0\n",
       "2  1313_1  and in the windows store you can flag the app ...      0\n",
       "3  1313_2  many thanks sameh hi as we know there is a lot...      0\n",
       "4  1313_3  the idea is that we can develop a regular app ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9566</td>\n",
       "      <td>this would enable live traffic aware apps</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9569</td>\n",
       "      <td>please try other formatting like bold italics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9576</td>\n",
       "      <td>since computers were invented to save time i s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9577</td>\n",
       "      <td>allow rearranging if the user wants to change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9579</td>\n",
       "      <td>add simd instructions for better use of arm ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           sentence  label\n",
       "0  9566          this would enable live traffic aware apps      0\n",
       "1  9569  please try other formatting like bold italics ...      1\n",
       "2  9576  since computers were invented to save time i s...      1\n",
       "3  9577  allow rearranging if the user wants to change ...      1\n",
       "4  9579  add simd instructions for better use of arm ne...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())\n",
    "display(eval_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr Params: max_df = 0.85 min_df = 0.01 vectorizer = count\n",
      "Curr Params: max_df = 0.85 min_df = 0.01 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.85 min_df = 0.02 vectorizer = count\n",
      "Curr Params: max_df = 0.85 min_df = 0.02 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.85 min_df = 0.03 vectorizer = count\n",
      "Curr Params: max_df = 0.85 min_df = 0.03 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.9 min_df = 0.01 vectorizer = count\n",
      "Curr Params: max_df = 0.9 min_df = 0.01 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.9 min_df = 0.02 vectorizer = count\n",
      "Curr Params: max_df = 0.9 min_df = 0.02 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.9 min_df = 0.03 vectorizer = count\n",
      "Curr Params: max_df = 0.9 min_df = 0.03 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.95 min_df = 0.01 vectorizer = count\n",
      "Curr Params: max_df = 0.95 min_df = 0.01 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.95 min_df = 0.02 vectorizer = count\n",
      "Curr Params: max_df = 0.95 min_df = 0.02 vectorizer = tfidf\n",
      "Curr Params: max_df = 0.95 min_df = 0.03 vectorizer = count\n",
      "Curr Params: max_df = 0.95 min_df = 0.03 vectorizer = tfidf\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "X = train_data['sentence']\n",
    "Y = train_data['label']\n",
    "max_df_ranges = [0.85, 0.9, 0.95] \n",
    "min_df_ranges = [0.01, 0.02, 0.03]\n",
    "vectorizers = [\"count\", \"tfidf\"]\n",
    "\n",
    "best_params = {}\n",
    "best_results = {} \n",
    "curr_best_f1 = float('-inf')\n",
    "\n",
    "for max_df in max_df_ranges:\n",
    "    for min_df in min_df_ranges:\n",
    "        for vectorizer in vectorizers:\n",
    "            f1_scores = []\n",
    "            recall_scores = []\n",
    "            accuracy_scores = []\n",
    "            precision_scores = []\n",
    "            print(f\"Curr Params: max_df = {max_df} min_df = {min_df} vectorizer = {vectorizer}\")\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "                if vectorizer == \"count\":\n",
    "                    vectorizer = CountVectorizer(max_df = max_df, min_df = min_df, ngram_range = (1,2))\n",
    "                else:\n",
    "                    vectorizer = TfidfVectorizer(max_df = max_df, min_df = min_df, ngram_range = (1,2))\n",
    "\n",
    "                vectorizer.fit(X_train)\n",
    "                X_train_vectorized = vectorizer.transform(X_train)\n",
    "                X_test_vectorized = vectorizer.transform(X_test)\n",
    "                clf = SVC()\n",
    "                clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "                Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "                f1_scores.append(f1_score(Y_test, Y_pred))\n",
    "                recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "                precision_scores.append(precision_score(Y_test, Y_pred))\n",
    "                accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "                mean_f1 = sum(f1_scores)/5\n",
    "                if mean_f1 > curr_best_f1:\n",
    "                    curr_best_f1 = mean_f1\n",
    "                    best_params['max_df'] = max_df\n",
    "                    best_params['min_df'] = min_df\n",
    "                    best_params['vectorizer'] = vectorizer\n",
    "                    best_results['f1'] = sum(f1_scores)/5\n",
    "                    best_results['precision'] = sum(precision_scores)/5\n",
    "                    best_results['recall'] = sum(recall_scores)/5\n",
    "                    best_results['accuracy'] = sum(accuracy_scores)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6660824124911213,\n",
       " 'precision': 0.7628831200390808,\n",
       " 'recall': 0.6079750692771972,\n",
       " 'accuracy': 0.8556470588235294}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_df': 0.85,\n",
       " 'min_df': 0.01,\n",
       " 'vectorizer': TfidfVectorizer(max_df=0.85, min_df=0.01, ngram_range=(1, 2))}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = best_params['max_df'], min_df = best_params['min_df'], ngram_range = (1,2))\n",
    "\n",
    "X_train = train_data['sentence']\n",
    "Y_train = train_data['label']\n",
    "\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "clf.fit(X_train_vectorized.toarray(), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5911949685534591\n",
      "Recall Score: 0.5402298850574713\n",
      "Precision Score: 0.6527777777777778\n",
      "Accuracy Score: 0.921968787515006\n"
     ]
    }
   ],
   "source": [
    "X_test = eval_data['sentence']\n",
    "Y_test = eval_data['label']\n",
    "\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision Score: {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 25 40 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[721,  25],\n",
       "       [ 40,  47]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "display(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr Params: C = 1 gammas = scale class_weights = balanced\n",
      "Curr Params: C = 1 gammas = scale class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 1 gammas = scale class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 1 gammas = scale class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 1 gammas = 1 class_weights = balanced\n",
      "Curr Params: C = 1 gammas = 1 class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 1 gammas = 1 class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 1 gammas = 1 class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 1 gammas = 2 class_weights = balanced\n",
      "Curr Params: C = 1 gammas = 2 class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 1 gammas = 2 class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 1 gammas = 2 class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 2 gammas = scale class_weights = balanced\n",
      "Curr Params: C = 2 gammas = scale class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 2 gammas = scale class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 2 gammas = scale class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 2 gammas = 1 class_weights = balanced\n",
      "Curr Params: C = 2 gammas = 1 class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 2 gammas = 1 class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 2 gammas = 1 class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 2 gammas = 2 class_weights = balanced\n",
      "Curr Params: C = 2 gammas = 2 class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 2 gammas = 2 class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 2 gammas = 2 class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 3 gammas = scale class_weights = balanced\n",
      "Curr Params: C = 3 gammas = scale class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 3 gammas = scale class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 3 gammas = scale class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 3 gammas = 1 class_weights = balanced\n",
      "Curr Params: C = 3 gammas = 1 class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 3 gammas = 1 class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 3 gammas = 1 class_weights = {0: 1, 1: 2.5}\n",
      "Curr Params: C = 3 gammas = 2 class_weights = balanced\n",
      "Curr Params: C = 3 gammas = 2 class_weights = {0: 1, 1: 2}\n",
      "Curr Params: C = 3 gammas = 2 class_weights = {0: 1, 1: 1.5}\n",
      "Curr Params: C = 3 gammas = 2 class_weights = {0: 1, 1: 2.5}\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "X = train_data['sentence']\n",
    "Y = train_data['label']tslack\n",
    "\n",
    "class_weights = ['balanced', {0:1, 1:2}, {0:1, 1:1.5}, {0:1,1:2.5}]\n",
    "gammas = ['scale',1,2,]\n",
    "Cs = [1,2,3]\n",
    "\n",
    "\n",
    "best_params = {}\n",
    "best_results = {} \n",
    "curr_best_f1 = float('-inf')\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "        for class_weight in class_weights:\n",
    "            f1_scores = []\n",
    "            recall_scores = []\n",
    "            accuracy_scores = []\n",
    "            precision_scores = []\n",
    "            print(f\"Curr Params: C = {C} gammas = {gamma} class_weights = {class_weight}\")\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "                vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "                vectorizer.fit(X_train)\n",
    "                X_train_vectorized = vectorizer.transform(X_train)\n",
    "                X_test_vectorized = vectorizer.transform(X_test)\n",
    "                clf = SVC(class_weight = class_weight, C = C, gamma = gamma)\n",
    "                clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "                Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "                f1_scores.append(f1_score(Y_test, Y_pred))\n",
    "                recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "                precision_scores.append(precision_score(Y_test, Y_pred))\n",
    "                accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "                mean_f1 = sum(f1_scores)/5\n",
    "                if mean_f1 > curr_best_f1:\n",
    "                    curr_best_f1 = mean_f1\n",
    "                    best_params['weight'] = class_weight\n",
    "                    best_params['gamma'] = gamma\n",
    "                    best_params['C'] = C\n",
    "                    best_results['f1'] = sum(f1_scores)/5\n",
    "                    best_results['precision'] = sum(precision_scores)/5\n",
    "                    best_results['recall'] = sum(recall_scores)/5\n",
    "                    best_results['accuracy'] = sum(accuracy_scores)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6939517284883424,\n",
       " 'precision': 0.6579642056460119,\n",
       " 'recall': 0.7577369423379058,\n",
       " 'accuracy': 0.8528235294117648}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': 'balanced', 'gamma': 1, 'C': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5650224215246638\n",
      "Recall Score: 0.7241379310344828\n",
      "Precision Score: 0.4632352941176471\n",
      "Accuracy Score: 0.8835534213685474\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(class_weight = best_params['weight'], C =  best_params['C'], gamma = best_params['gamma'])\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "\n",
    "X_train = train_data['sentence']\n",
    "Y_train = train_data['label']\n",
    "\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "\n",
    "X_test = eval_data['sentence']\n",
    "Y_test = eval_data['label']\n",
    "\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision Score: {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673 73 24 63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[673,  73],\n",
       "       [ 24,  63]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "display(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree = 2 class weight = balanced\n",
      "degree = 2 class weight = None\n",
      "degree = 3 class weight = balanced\n",
      "degree = 3 class weight = None\n",
      "degree = 4 class weight = balanced\n",
      "degree = 4 class weight = None\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5)\n",
    "X = train_data['sentence']\n",
    "Y = train_data['label']\n",
    "\n",
    "class_weights = ['balanced', None]\n",
    "degrees = [2,3,4]\n",
    "\n",
    "\n",
    "best_params = {}\n",
    "best_results = {} \n",
    "curr_best_f1 = float('-inf')\n",
    "\n",
    "for deg in degrees:\n",
    "    for class_weight in class_weights:\n",
    "        f1_scores = []\n",
    "        recall_scores = []\n",
    "        accuracy_scores = []\n",
    "        precision_scores = []\n",
    "        print(f\"degree = {deg} class weight = {class_weight}\")\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "            vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "            vectorizer.fit(X_train)\n",
    "            X_train_vectorized = vectorizer.transform(X_train)\n",
    "            X_test_vectorized = vectorizer.transform(X_test)\n",
    "            clf = SVC(kernel = 'poly', class_weight = class_weight, degree = deg)\n",
    "            clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "            Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "            f1_scores.append(f1_score(Y_test, Y_pred))\n",
    "            recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "            precision_scores.append(precision_score(Y_test, Y_pred))\n",
    "            accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "            mean_f1 = sum(f1_scores)/5\n",
    "            if mean_f1 > curr_best_f1:\n",
    "                curr_best_f1 = mean_f1\n",
    "                best_params['weight'] = class_weight\n",
    "                best_params['degree'] = deg\n",
    "                best_results['f1'] = sum(f1_scores)/5\n",
    "                best_results['precision'] = sum(precision_scores)/5\n",
    "                best_results['recall'] = sum(recall_scores)/5\n",
    "                best_results['accuracy'] = sum(accuracy_scores)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': 'balanced', 'degree': 2}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6746838100020767,\n",
       " 'precision': 0.6601056031454443,\n",
       " 'recall': 0.7129435896535296,\n",
       " 'accuracy': 0.8471764705882352}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5544554455445545\n",
      "Recall Score: 0.6436781609195402\n",
      "Precision Score: 0.48695652173913045\n",
      "Accuracy Score: 0.8919567827130852\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel = 'poly', class_weight = best_params['weight'], degree = best_params['degree'])\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "\n",
    "X_train = train_data['sentence']\n",
    "Y_train = train_data['label']\n",
    "\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "\n",
    "X_test = eval_data['sentence']\n",
    "Y_test = eval_data['label']\n",
    "\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision Score: {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 59 31 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[687,  59],\n",
       "       [ 31,  56]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "display(confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 01:47:46,409]\u001b[0m A new study created in memory with name: no-name-77c8e512-07b9-4ee0-a32f-ae0c32d4b35a\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:49:39,879]\u001b[0m Trial 0 finished with value: 0.6414523449319214 and parameters: {'n_estimators': 843, 'max_depth': 10, 'learning_rate': 0.06216023933264048, 'reg_lambda': 0.31096684141469466}. Best is trial 0 with value: 0.6414523449319214.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:50:42,615]\u001b[0m Trial 1 finished with value: 0.6533127889060092 and parameters: {'n_estimators': 618, 'max_depth': 7, 'learning_rate': 0.08067371311680485, 'reg_lambda': 1.7024272085976702}. Best is trial 1 with value: 0.6533127889060092.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:51:14,521]\u001b[0m Trial 2 finished with value: 0.6483870967741935 and parameters: {'n_estimators': 346, 'max_depth': 6, 'learning_rate': 0.02534252016855842, 'reg_lambda': 0.9987680244323739}. Best is trial 1 with value: 0.6533127889060092.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:52:29,022]\u001b[0m Trial 3 finished with value: 0.6583850931677019 and parameters: {'n_estimators': 461, 'max_depth': 12, 'learning_rate': 0.02657278565962561, 'reg_lambda': 0.5591641519745094}. Best is trial 3 with value: 0.6583850931677019.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:54:44,451]\u001b[0m Trial 4 finished with value: 0.6646525679758308 and parameters: {'n_estimators': 851, 'max_depth': 12, 'learning_rate': 0.06257580544191949, 'reg_lambda': 1.7017677355674228}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:55:43,171]\u001b[0m Trial 5 finished with value: 0.6540880503144654 and parameters: {'n_estimators': 469, 'max_depth': 9, 'learning_rate': 0.029237700577656275, 'reg_lambda': 1.0756733114649524}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:56:16,246]\u001b[0m Trial 6 finished with value: 0.6624605678233437 and parameters: {'n_estimators': 237, 'max_depth': 10, 'learning_rate': 0.037406991380453086, 'reg_lambda': 1.5904310021275399}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:57:32,161]\u001b[0m Trial 7 finished with value: 0.6591639871382636 and parameters: {'n_estimators': 602, 'max_depth': 9, 'learning_rate': 0.014391564729019188, 'reg_lambda': 1.8723314402497746}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:58:48,786]\u001b[0m Trial 8 finished with value: 0.6635944700460831 and parameters: {'n_estimators': 686, 'max_depth': 8, 'learning_rate': 0.0913423313196365, 'reg_lambda': 1.885297035371773}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 01:59:40,996]\u001b[0m Trial 9 finished with value: 0.6496815286624203 and parameters: {'n_estimators': 967, 'max_depth': 3, 'learning_rate': 0.07438918805003192, 'reg_lambda': 0.1052118391396427}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:01:47,199]\u001b[0m Trial 10 finished with value: 0.6646433990895295 and parameters: {'n_estimators': 794, 'max_depth': 12, 'learning_rate': 0.05365182361484659, 'reg_lambda': 1.353129414491206}. Best is trial 4 with value: 0.6646525679758308.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:03:52,316]\u001b[0m Trial 11 finished with value: 0.665648854961832 and parameters: {'n_estimators': 784, 'max_depth': 12, 'learning_rate': 0.05253519132360042, 'reg_lambda': 1.2919594353796535}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:06:21,953]\u001b[0m Trial 12 finished with value: 0.6606060606060605 and parameters: {'n_estimators': 942, 'max_depth': 12, 'learning_rate': 0.06114982916264004, 'reg_lambda': 1.339796424813011}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:08:16,275]\u001b[0m Trial 13 finished with value: 0.6514459665144596 and parameters: {'n_estimators': 767, 'max_depth': 11, 'learning_rate': 0.04638872448712514, 'reg_lambda': 0.9005200930775734}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:09:15,064]\u001b[0m Trial 14 finished with value: 0.5982300884955752 and parameters: {'n_estimators': 871, 'max_depth': 4, 'learning_rate': 0.003265061511770556, 'reg_lambda': 1.5181700246037109}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:11:00,482]\u001b[0m Trial 15 finished with value: 0.6596066565809379 and parameters: {'n_estimators': 716, 'max_depth': 11, 'learning_rate': 0.07604353668989393, 'reg_lambda': 1.224172737124157}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:12:28,850]\u001b[0m Trial 16 finished with value: 0.6506024096385543 and parameters: {'n_estimators': 991, 'max_depth': 6, 'learning_rate': 0.0963209990427219, 'reg_lambda': 0.7550800722609907}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:14:01,429]\u001b[0m Trial 17 finished with value: 0.664624808575804 and parameters: {'n_estimators': 679, 'max_depth': 10, 'learning_rate': 0.04721755906316692, 'reg_lambda': 1.716118581290853}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:15:18,735]\u001b[0m Trial 18 finished with value: 0.665648854961832 and parameters: {'n_estimators': 522, 'max_depth': 11, 'learning_rate': 0.06577195175255893, 'reg_lambda': 1.4682219257759264}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:15:37,206]\u001b[0m Trial 19 finished with value: 0.6625 and parameters: {'n_estimators': 120, 'max_depth': 11, 'learning_rate': 0.07098218537141154, 'reg_lambda': 1.204413736806642}. Best is trial 11 with value: 0.665648854961832.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:16:33,659]\u001b[0m Trial 20 finished with value: 0.6686838124054464 and parameters: {'n_estimators': 497, 'max_depth': 8, 'learning_rate': 0.08629314631881962, 'reg_lambda': 1.4482713860109766}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:17:29,212]\u001b[0m Trial 21 finished with value: 0.6605222734254992 and parameters: {'n_estimators': 488, 'max_depth': 8, 'learning_rate': 0.08453807725609001, 'reg_lambda': 1.4958803672721406}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:18:16,494]\u001b[0m Trial 22 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 378, 'max_depth': 9, 'learning_rate': 0.09970871570953586, 'reg_lambda': 1.30407450634287}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:19:01,026]\u001b[0m Trial 23 finished with value: 0.6584992343032159 and parameters: {'n_estimators': 355, 'max_depth': 9, 'learning_rate': 0.09042244141646703, 'reg_lambda': 1.4479997654836352}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:19:37,267]\u001b[0m Trial 24 finished with value: 0.6574500768049155 and parameters: {'n_estimators': 357, 'max_depth': 7, 'learning_rate': 0.09982609121413513, 'reg_lambda': 1.1804317477234614}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:20:13,273]\u001b[0m Trial 25 finished with value: 0.660436137071651 and parameters: {'n_estimators': 403, 'max_depth': 6, 'learning_rate': 0.08555613825659016, 'reg_lambda': 0.8108751463528671}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:21:16,485]\u001b[0m Trial 26 finished with value: 0.6533742331288342 and parameters: {'n_estimators': 560, 'max_depth': 8, 'learning_rate': 0.06653555285094885, 'reg_lambda': 1.9976578996449539}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:21:48,783]\u001b[0m Trial 27 finished with value: 0.6676970633693972 and parameters: {'n_estimators': 260, 'max_depth': 9, 'learning_rate': 0.08958136814319778, 'reg_lambda': 1.0959806944589885}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:22:19,569]\u001b[0m Trial 28 finished with value: 0.6676923076923077 and parameters: {'n_estimators': 246, 'max_depth': 9, 'learning_rate': 0.09262853943029141, 'reg_lambda': 1.0695283927972654}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:22:51,797]\u001b[0m Trial 29 finished with value: 0.6677067082683308 and parameters: {'n_estimators': 232, 'max_depth': 10, 'learning_rate': 0.09009261079195924, 'reg_lambda': 0.5423412915851428}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:23:09,384]\u001b[0m Trial 30 finished with value: 0.6457680250783698 and parameters: {'n_estimators': 124, 'max_depth': 10, 'learning_rate': 0.08898458121185966, 'reg_lambda': 0.5371960668767751}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 02:23:41,568]\u001b[0m Trial 31 finished with value: 0.654434250764526 and parameters: {'n_estimators': 232, 'max_depth': 10, 'learning_rate': 0.08221791111709822, 'reg_lambda': 0.6117583581670009}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:24:05,457]\u001b[0m Trial 32 finished with value: 0.660436137071651 and parameters: {'n_estimators': 232, 'max_depth': 7, 'learning_rate': 0.07790535959355319, 'reg_lambda': 0.35453750070317824}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:24:36,898]\u001b[0m Trial 33 finished with value: 0.6625577812018489 and parameters: {'n_estimators': 275, 'max_depth': 8, 'learning_rate': 0.09303946604046916, 'reg_lambda': 1.0501993340931988}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:25:13,266]\u001b[0m Trial 34 finished with value: 0.6635658914728682 and parameters: {'n_estimators': 293, 'max_depth': 9, 'learning_rate': 0.08241511180807155, 'reg_lambda': 0.9264966948900104}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:25:39,273]\u001b[0m Trial 35 finished with value: 0.6584234930448223 and parameters: {'n_estimators': 186, 'max_depth': 10, 'learning_rate': 0.08817459564874439, 'reg_lambda': 0.7336423695380305}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:26:01,462]\u001b[0m Trial 36 finished with value: 0.6529968454258676 and parameters: {'n_estimators': 175, 'max_depth': 9, 'learning_rate': 0.09533417008873336, 'reg_lambda': 1.1104731704504383}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:26:27,641]\u001b[0m Trial 37 finished with value: 0.6635220125786163 and parameters: {'n_estimators': 289, 'max_depth': 6, 'learning_rate': 0.07124419525087773, 'reg_lambda': 0.9671765075753243}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:27:11,049]\u001b[0m Trial 38 finished with value: 0.6615853658536585 and parameters: {'n_estimators': 428, 'max_depth': 7, 'learning_rate': 0.08003314047094146, 'reg_lambda': 0.34962063674654986}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:27:24,266]\u001b[0m Trial 39 finished with value: 0.6363636363636364 and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.09381461831564686, 'reg_lambda': 0.1610184258912215}. Best is trial 20 with value: 0.6686838124054464.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:27:59,548]\u001b[0m Trial 40 finished with value: 0.6729559748427674 and parameters: {'n_estimators': 315, 'max_depth': 8, 'learning_rate': 0.0853649815664241, 'reg_lambda': 0.8573402774150938}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:28:35,851]\u001b[0m Trial 41 finished with value: 0.6584234930448223 and parameters: {'n_estimators': 321, 'max_depth': 8, 'learning_rate': 0.08715326084283566, 'reg_lambda': 0.519161486229238}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:29:08,079]\u001b[0m Trial 42 finished with value: 0.6646058732612056 and parameters: {'n_estimators': 251, 'max_depth': 9, 'learning_rate': 0.0782655323200618, 'reg_lambda': 0.6469818379048453}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:29:31,609]\u001b[0m Trial 43 finished with value: 0.658267716535433 and parameters: {'n_estimators': 205, 'max_depth': 8, 'learning_rate': 0.08394582420550849, 'reg_lambda': 0.4482133271336284}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:30:29,700]\u001b[0m Trial 44 finished with value: 0.6646433990895295 and parameters: {'n_estimators': 428, 'max_depth': 10, 'learning_rate': 0.07311358556517092, 'reg_lambda': 0.8806806770682108}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:31:08,904]\u001b[0m Trial 45 finished with value: 0.6548956661316213 and parameters: {'n_estimators': 315, 'max_depth': 9, 'learning_rate': 0.032388713502220584, 'reg_lambda': 1.0425374674083037}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:32:07,831]\u001b[0m Trial 46 finished with value: 0.6534351145038167 and parameters: {'n_estimators': 587, 'max_depth': 7, 'learning_rate': 0.09720360280306246, 'reg_lambda': 1.1355361175540406}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:32:26,990]\u001b[0m Trial 47 finished with value: 0.6635514018691588 and parameters: {'n_estimators': 148, 'max_depth': 9, 'learning_rate': 0.09121647788536472, 'reg_lambda': 1.6274112081177814}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:32:56,627]\u001b[0m Trial 48 finished with value: 0.6456692913385826 and parameters: {'n_estimators': 258, 'max_depth': 8, 'learning_rate': 0.05811762329215097, 'reg_lambda': 0.8449360187829678}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:34:03,392]\u001b[0m Trial 49 finished with value: 0.6717791411042945 and parameters: {'n_estimators': 491, 'max_depth': 10, 'learning_rate': 0.0688890265203371, 'reg_lambda': 0.9689746873937198}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:35:12,141]\u001b[0m Trial 50 finished with value: 0.6554878048780488 and parameters: {'n_estimators': 506, 'max_depth': 10, 'learning_rate': 0.0683996788641869, 'reg_lambda': 0.6841555524447541}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:36:10,927]\u001b[0m Trial 51 finished with value: 0.6595419847328244 and parameters: {'n_estimators': 432, 'max_depth': 10, 'learning_rate': 0.07563754670039394, 'reg_lambda': 1.4040641737711281}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:37:19,379]\u001b[0m Trial 52 finished with value: 0.6585365853658537 and parameters: {'n_estimators': 461, 'max_depth': 11, 'learning_rate': 0.0865934475678187, 'reg_lambda': 1.014324281611837}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:37:47,872]\u001b[0m Trial 53 finished with value: 0.6573208722741433 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.08072065977569817, 'reg_lambda': 1.2467852781115532}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:39:29,975]\u001b[0m Trial 54 finished with value: 0.662613981762918 and parameters: {'n_estimators': 658, 'max_depth': 11, 'learning_rate': 0.09185715879072985, 'reg_lambda': 0.7824516900069021}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:40:06,942]\u001b[0m Trial 55 finished with value: 0.6697965571205008 and parameters: {'n_estimators': 328, 'max_depth': 8, 'learning_rate': 0.061016378640309385, 'reg_lambda': 1.1500118253039906}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:41:06,294]\u001b[0m Trial 56 finished with value: 0.6604938271604939 and parameters: {'n_estimators': 532, 'max_depth': 8, 'learning_rate': 0.05860825400219305, 'reg_lambda': 0.952870420400183}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:41:45,511]\u001b[0m Trial 57 finished with value: 0.6435331230283912 and parameters: {'n_estimators': 385, 'max_depth': 7, 'learning_rate': 0.041644399514015745, 'reg_lambda': 1.1510832139822615}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:42:21,677]\u001b[0m Trial 58 finished with value: 0.6540284360189573 and parameters: {'n_estimators': 317, 'max_depth': 8, 'learning_rate': 0.05416126679130222, 'reg_lambda': 1.582221632838829}. Best is trial 40 with value: 0.6729559748427674.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:43:26,318]\u001b[0m Trial 59 finished with value: 0.6769230769230768 and parameters: {'n_estimators': 476, 'max_depth': 10, 'learning_rate': 0.06304971145218723, 'reg_lambda': 1.363541219512416}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:45:06,478]\u001b[0m Trial 60 finished with value: 0.6574923547400612 and parameters: {'n_estimators': 625, 'max_depth': 12, 'learning_rate': 0.06380495804124428, 'reg_lambda': 1.338147967427853}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:46:12,862]\u001b[0m Trial 61 finished with value: 0.6542635658914728 and parameters: {'n_estimators': 486, 'max_depth': 10, 'learning_rate': 0.06043859289988869, 'reg_lambda': 1.2831770500531199}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 02:47:29,190]\u001b[0m Trial 62 finished with value: 0.664624808575804 and parameters: {'n_estimators': 560, 'max_depth': 10, 'learning_rate': 0.06712195640747076, 'reg_lambda': 1.4113608210207143}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:48:21,432]\u001b[0m Trial 63 finished with value: 0.6490683229813664 and parameters: {'n_estimators': 350, 'max_depth': 11, 'learning_rate': 0.05489988238767769, 'reg_lambda': 1.2133835870375957}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:49:18,434]\u001b[0m Trial 64 finished with value: 0.6687211093990754 and parameters: {'n_estimators': 455, 'max_depth': 9, 'learning_rate': 0.07046685334561835, 'reg_lambda': 1.8008229543801773}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:50:04,296]\u001b[0m Trial 65 finished with value: 0.6593406593406593 and parameters: {'n_estimators': 403, 'max_depth': 8, 'learning_rate': 0.04772594377678098, 'reg_lambda': 1.724659974979347}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:50:29,139]\u001b[0m Trial 66 finished with value: 0.6527999999999999 and parameters: {'n_estimators': 455, 'max_depth': 3, 'learning_rate': 0.07074673340423107, 'reg_lambda': 1.7916091809112096}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:51:35,582]\u001b[0m Trial 67 finished with value: 0.6529318541996831 and parameters: {'n_estimators': 528, 'max_depth': 9, 'learning_rate': 0.021652794209946525, 'reg_lambda': 1.914782882578248}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:52:24,062]\u001b[0m Trial 68 finished with value: 0.6646153846153846 and parameters: {'n_estimators': 482, 'max_depth': 7, 'learning_rate': 0.06322027103391233, 'reg_lambda': 1.5397023321584058}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:53:44,099]\u001b[0m Trial 69 finished with value: 0.6625766871165644 and parameters: {'n_estimators': 586, 'max_depth': 10, 'learning_rate': 0.050380310640546995, 'reg_lambda': 1.6483932857245103}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:54:41,292]\u001b[0m Trial 70 finished with value: 0.6636085626911314 and parameters: {'n_estimators': 387, 'max_depth': 11, 'learning_rate': 0.07376487675148849, 'reg_lambda': 1.812298411949975}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:55:38,298]\u001b[0m Trial 71 finished with value: 0.6208053691275168 and parameters: {'n_estimators': 448, 'max_depth': 9, 'learning_rate': 0.002673769495457369, 'reg_lambda': 0.9832714824596243}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:55:51,529]\u001b[0m Trial 72 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 101, 'max_depth': 9, 'learning_rate': 0.07687843398268648, 'reg_lambda': 1.0855035116367806}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:56:14,957]\u001b[0m Trial 73 finished with value: 0.6562009419152277 and parameters: {'n_estimators': 206, 'max_depth': 8, 'learning_rate': 0.06972384302436219, 'reg_lambda': 1.260287923664731}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:57:00,443]\u001b[0m Trial 74 finished with value: 0.6676970633693972 and parameters: {'n_estimators': 328, 'max_depth': 10, 'learning_rate': 0.05690065045225626, 'reg_lambda': 0.257234705086401}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:57:46,440]\u001b[0m Trial 75 finished with value: 0.6584615384615385 and parameters: {'n_estimators': 334, 'max_depth': 10, 'learning_rate': 0.05843494902147655, 'reg_lambda': 0.19321251886147583}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:58:42,284]\u001b[0m Trial 76 finished with value: 0.6523076923076924 and parameters: {'n_estimators': 406, 'max_depth': 10, 'learning_rate': 0.06554819408037926, 'reg_lambda': 0.22863391493699367}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 02:59:37,202]\u001b[0m Trial 77 finished with value: 0.6522411128284389 and parameters: {'n_estimators': 369, 'max_depth': 11, 'learning_rate': 0.05560273592373553, 'reg_lambda': 0.4264926210744375}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:00:14,084]\u001b[0m Trial 78 finished with value: 0.671850699844479 and parameters: {'n_estimators': 293, 'max_depth': 9, 'learning_rate': 0.08262015993424683, 'reg_lambda': 1.3725211624905298}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:00:46,832]\u001b[0m Trial 79 finished with value: 0.6677067082683308 and parameters: {'n_estimators': 293, 'max_depth': 8, 'learning_rate': 0.0799400273896651, 'reg_lambda': 1.3602402764920687}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:01:19,900]\u001b[0m Trial 80 finished with value: 0.6645865834633385 and parameters: {'n_estimators': 288, 'max_depth': 8, 'learning_rate': 0.07988769122762013, 'reg_lambda': 1.391819795770286}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:01:53,110]\u001b[0m Trial 81 finished with value: 0.6522411128284389 and parameters: {'n_estimators': 297, 'max_depth': 8, 'learning_rate': 0.08428003938949592, 'reg_lambda': 1.4840781556167288}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:02:55,813]\u001b[0m Trial 82 finished with value: 0.6605222734254992 and parameters: {'n_estimators': 507, 'max_depth': 9, 'learning_rate': 0.0731342795801674, 'reg_lambda': 1.3272422458608075}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:03:57,456]\u001b[0m Trial 83 finished with value: 0.6615853658536585 and parameters: {'n_estimators': 550, 'max_depth': 8, 'learning_rate': 0.08279055997494938, 'reg_lambda': 1.4520197485919184}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:04:24,030]\u001b[0m Trial 84 finished with value: 0.6625194401244168 and parameters: {'n_estimators': 209, 'max_depth': 9, 'learning_rate': 0.07828954202629408, 'reg_lambda': 1.5521081358874165}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:04:50,913]\u001b[0m Trial 85 finished with value: 0.6457680250783698 and parameters: {'n_estimators': 267, 'max_depth': 7, 'learning_rate': 0.08876236964159709, 'reg_lambda': 1.1699597519810843}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:05:26,562]\u001b[0m Trial 86 finished with value: 0.6687598116169545 and parameters: {'n_estimators': 352, 'max_depth': 7, 'learning_rate': 0.06100928561031354, 'reg_lambda': 1.3586457192195667}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:06:01,737]\u001b[0m Trial 87 finished with value: 0.6614664586583463 and parameters: {'n_estimators': 352, 'max_depth': 7, 'learning_rate': 0.0621782706575952, 'reg_lambda': 0.7213190408685969}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:06:38,248]\u001b[0m Trial 88 finished with value: 0.6677067082683308 and parameters: {'n_estimators': 414, 'max_depth': 6, 'learning_rate': 0.06837662171041081, 'reg_lambda': 1.374398994290548}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:07:18,207]\u001b[0m Trial 89 finished with value: 0.6561514195583596 and parameters: {'n_estimators': 441, 'max_depth': 6, 'learning_rate': 0.06051689109151053, 'reg_lambda': 0.875071470890499}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:07:49,386]\u001b[0m Trial 90 finished with value: 0.6496 and parameters: {'n_estimators': 398, 'max_depth': 5, 'learning_rate': 0.0648303085915718, 'reg_lambda': 1.509998924559254}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:08:26,475]\u001b[0m Trial 91 finished with value: 0.65818759936407 and parameters: {'n_estimators': 475, 'max_depth': 5, 'learning_rate': 0.06956199304587496, 'reg_lambda': 1.4046623105573743}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:09:03,678]\u001b[0m Trial 92 finished with value: 0.6604651162790697 and parameters: {'n_estimators': 414, 'max_depth': 6, 'learning_rate': 0.09708654897907597, 'reg_lambda': 1.2714370552119998}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 03:09:36,796]\u001b[0m Trial 93 finished with value: 0.6635071090047393 and parameters: {'n_estimators': 366, 'max_depth': 6, 'learning_rate': 0.06812143798379372, 'reg_lambda': 1.2196917160963807}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:10:28,234]\u001b[0m Trial 94 finished with value: 0.6575342465753425 and parameters: {'n_estimators': 512, 'max_depth': 7, 'learning_rate': 0.074783927166034, 'reg_lambda': 1.033261003201417}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:11:02,074]\u001b[0m Trial 95 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.08603228266838206, 'reg_lambda': 0.5963048006904113}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:11:36,473]\u001b[0m Trial 96 finished with value: 0.6625577812018489 and parameters: {'n_estimators': 273, 'max_depth': 9, 'learning_rate': 0.08116110110225463, 'reg_lambda': 1.3280639105311176}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:12:23,343]\u001b[0m Trial 97 finished with value: 0.655436447166922 and parameters: {'n_estimators': 467, 'max_depth': 7, 'learning_rate': 0.09482770795133896, 'reg_lambda': 1.443123765546643}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:13:24,566]\u001b[0m Trial 98 finished with value: 0.6676923076923077 and parameters: {'n_estimators': 495, 'max_depth': 9, 'learning_rate': 0.05265396967193076, 'reg_lambda': 1.6691504053100596}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 03:14:11,879]\u001b[0m Trial 99 finished with value: 0.6553323029366306 and parameters: {'n_estimators': 424, 'max_depth': 8, 'learning_rate': 0.07127305010623404, 'reg_lambda': 1.3755452105329136}. Best is trial 59 with value: 0.6769230769230768.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X = train_data['sentence']\n",
    "Y = train_data['label']\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000) \n",
    "    max_depth = trial.suggest_int('max_depth', 3, 12)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0.1, 2)\n",
    "    kf = KFold(n_splits = 5)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "        vectorizer.fit(X_train)\n",
    "        X_train_vectorized = vectorizer.transform(X_train)\n",
    "        X_test_vectorized = vectorizer.transform(X_test)\n",
    "        clf = xgboost.XGBClassifier(n_estimators = n_estimators, max_depth = max_depth, learning_rate = learning_rate, reg_lambda = reg_lambda)\n",
    "        clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "        Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "        return f1_score(Y_test, Y_pred)\n",
    "    \n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.673124126514214\n",
      "Recall Score: 0.6470449363871446\n",
      "Precision Score: 0.7257001988397525\n",
      "Accuracy Score: 0.8552941176470588\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "X = train_data['sentence']\n",
    "Y = train_data['label']\n",
    "\n",
    "kf = KFold(n_splits = 5)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "    vectorizer.fit(X_train)\n",
    "    X_train_vectorized = vectorizer.transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    clf = xgboost.XGBClassifier(n_estimators = 476, max_depth = 10, learning_rate = 0.06304971145218723, reg_lambda = 1.363541219512416)\n",
    "    clf.fit(X_train_vectorized.toarray(), Y_train)\n",
    "    Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "    \n",
    "    f1_scores.append(f1_score(Y_test, Y_pred))\n",
    "    recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "    precision_scores.append(precision_score(Y_test, Y_pred))\n",
    "    accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "print(f\"F1 Score: {sum(f1_scores)/5}\")\n",
    "print(f\"Recall Score: {sum(recall_scores)/5}\")\n",
    "print(f\"Precision Score: {sum(precision_scores)/5}\")\n",
    "print(f\"Accuracy Score: {sum(accuracy_scores)/5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 476,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.06304971145218723,\n",
       " 'reg_lambda': 1.363541219512416}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 451,\n",
       " 'max_depth': 9,\n",
       " 'learning_rate': 0.07927128145186134,\n",
       " 'reg_lambda': 1.477291705778975}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.5664739884393063\n",
      "Recall Score: 0.5632183908045977\n",
      "Precision Score: 0.5697674418604651\n",
      "Accuracy Score: 0.9099639855942377\n"
     ]
    }
   ],
   "source": [
    "vect = vectorizer = TfidfVectorizer(max_df = 0.85, min_df = 0.01, ngram_range = (1,2))\n",
    "clf = xgboost.XGBClassifier(n_estimators = study.best_params['n_estimators'],\n",
    "                           max_depth = study.best_params['max_depth'],\n",
    "                           learning_rate = study.best_params['learning_rate'],\n",
    "                           reg_lambda = study.best_params['reg_lambda'])\n",
    "\n",
    "vect.fit(X)\n",
    "X_test, Y_test = eval_data['sentence'], eval_data['label']\n",
    "X_train_vectorized = vect.transform(X)\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized.toarray(), Y)\n",
    "Y_pred = clf.predict(X_test_vectorized.toarray())\n",
    "\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"Recall Score: {recall_score(Y_test, Y_pred)}\")\n",
    "print(f\"Precision Score: {precision_score(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(Y_test, Y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[709,  37],\n",
       "       [ 38,  49]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall summary of results of Naive Bayes and SVM\n",
    "\n",
    "Overall, we have 3 main results <br>\n",
    "1. TF-IDF with Gaussian NB\n",
    "2. Count Vectorizer with Multinomial NB\n",
    "3. TF-IDF with SVM \n",
    "\n",
    "\n",
    "### Cross Validation Scores\n",
    "\n",
    "|Model|F1 Score|Precision|Recall|Accuracy|\n",
    "|---|---|---|---|---|\n",
    "|TF-IDF with Gaussian NB| 0.5517 | 0.4512 | 0.7792 | 0.7360 |  \n",
    "|BOW with Multinomial NB| 0.6336 | 0.6483 | 0.6423 | 0.8355 |\n",
    "|TF-IDF with SVM Radial| 0.6940 | 0.6580 | 0.7577 | 0.8528 |\n",
    "|TF-IDF with SVM Polynomial| 0.6747 | 0.6601 | 0.7129 | 0.8834 |\n",
    "|XG Boost | 0.6731 | 0.7257 | 0.6470 | 0.8553 |\n",
    "\n",
    "\n",
    "### Test Set Scores\n",
    "\n",
    "|Model|F1 Score|Precision|Recall|Accuracy|\n",
    "|---|---|---|---|---|\n",
    "|TF-IDF with Gaussian NB| 0.4012 | 0.2685 | 0.7931 | 0.7527 |  \n",
    "|BOW with Multinomial NB| 0.5714 | 0.5294 | 0.6207 | 0.9028 |\n",
    "|TF-IDF with SVM Radial | 0.5650 | 0.4632 | 0.7241 | 0.8836 |\n",
    "|TF-IDF with SVM Polynomial| 0.5545 | 0.4870 | 0.6437 | 0.8920 |\n",
    "|XG Boost | 0.5664 | 0.5632 | 0.5697 | 0.9100 | \n",
    "\n",
    "\n",
    "### Test Set Confusion Matrices\n",
    "\n",
    "###### TF-IDF with Gaussian NB\n",
    "||Predict Negative|Predict Positive|\n",
    "|---|---|---|\n",
    "|Actual Negative|558|188|\n",
    "|Actual Positive|18|69|\n",
    "\n",
    "###### Count Vectorizer with Multinomial NB\n",
    "||Predict Negative|Predict Positive|\n",
    "|---|---|---|\n",
    "|Actual Negative|698|48|\n",
    "|Actual Positive|33|54|\n",
    "\n",
    "###### TF-IDF with SVM Radial\n",
    "||Predict Negative|Predict Positive|\n",
    "|---|---|---|\n",
    "|Actual Negative|673|73|\n",
    "|Actual Positive|24|63|\n",
    "\n",
    "###### TF-IDF with SVM Polynomial\n",
    "||Predict Negative|Predict Positive|\n",
    "|---|---|---|\n",
    "|Actual Negative|687|59|\n",
    "|Actual Positive|31|56|\n",
    "\n",
    "##### XG Boost \n",
    "||Predict Negative|Predict Positive|\n",
    "|---|---|---|\n",
    "|Actual Negative|709|37|\n",
    "|Actual Positive|38|49|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
