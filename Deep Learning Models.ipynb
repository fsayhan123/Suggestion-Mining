{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHYWdIMo3-C_"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBePo8TlilQH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "import string \n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "from textblob import Word, TextBlob\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Bidirectional, Attention, Concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yQILu1r7MB5"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A51PnP2XVisy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILsM2b5ViwNV",
        "outputId": "d9fbd5b6-b2c7-4814-896e-6fbcc9503888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxIqsjJ8k1vd"
      },
      "source": [
        "### Data Loading and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f3xkMP7k4dz"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/drive/MyDrive/FYP Model Training'\n",
        "train_data = pd.read_csv(f'{root_dir}/Data/App_Training.csv')\n",
        "test_data = pd.read_csv(f'{root_dir}/Data/App_Test_Labeled.csv')\n",
        "eval_data = pd.read_csv(f'{root_dir}/Data/SubtaskA_EvaluationData_labeled.csv', header = None, encoding = 'latin1')\n",
        "eval_data.columns = ['id', 'sentence', 'label']\n",
        "\n",
        "train_data.drop(labels = ['0'], axis = 1, inplace = True)\n",
        "test_data.drop(labels = ['0'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Y7C1on4f6SWk",
        "outputId": "ca8696e7-fc8f-450d-9878-11024e41a35e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                           sentence  label\n",
              "0      663_3   Please enable removing language code from the...      1\n",
              "1      663_4   Note in your csproj file there is a Supported...      0\n",
              "2      664_1   Wich means the new version not fully replaced...      0\n",
              "3      664_2   Some of my users will still receive the old x...      0\n",
              "4      664_3   The store randomly gives the old xap or the n...      0\n",
              "...      ...                                                ...    ...\n",
              "9087  1658_3  we should have small tiles instead of a long l...      1\n",
              "9088  1658_7  An app should be able to publish a service tha...      1\n",
              "9089  1658_8  For example if I have an app that can process ...      1\n",
              "9090  1659_1  I would like access to a stream for music play...      1\n",
              "9091  1660_1  i wish the functionality to access and synchro...      1\n",
              "\n",
              "[9092 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97f97e74-cde9-4566-a956-915577ec3ef3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>663_3</td>\n",
              "      <td>Please enable removing language code from the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>663_4</td>\n",
              "      <td>Note in your csproj file there is a Supported...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>664_1</td>\n",
              "      <td>Wich means the new version not fully replaced...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>664_2</td>\n",
              "      <td>Some of my users will still receive the old x...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>664_3</td>\n",
              "      <td>The store randomly gives the old xap or the n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9087</th>\n",
              "      <td>1658_3</td>\n",
              "      <td>we should have small tiles instead of a long l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9088</th>\n",
              "      <td>1658_7</td>\n",
              "      <td>An app should be able to publish a service tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9089</th>\n",
              "      <td>1658_8</td>\n",
              "      <td>For example if I have an app that can process ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9090</th>\n",
              "      <td>1659_1</td>\n",
              "      <td>I would like access to a stream for music play...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9091</th>\n",
              "      <td>1660_1</td>\n",
              "      <td>i wish the functionality to access and synchro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9092 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97f97e74-cde9-4566-a956-915577ec3ef3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97f97e74-cde9-4566-a956-915577ec3ef3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97f97e74-cde9-4566-a956-915577ec3ef3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "train_data = pd.concat([train_data, test_data]).copy().reset_index(drop = True)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvS6JDuWlnfb"
      },
      "outputs": [],
      "source": [
        "train_data['sentence'] = train_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
        "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: \" \".join([word.lower() for word in x.split()]))\n",
        "\n",
        "train_data['sentence'] = train_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
        "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['sentence'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QShtz7CWvN2i",
        "outputId": "8088ae53-3f72-487c-9768-ea347d557275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'please enable removing language code from the dev center language history for example if you ever selected ru and ru ru laguages and you published this xap to the store then it causes tile localization to show the en us default tile localization which is bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to apply auto spell check according to TextBlob's correct() function\n",
        "train_data['sentence'] = train_data['sentence'].apply(lambda x: TextBlob(x).correct().raw)\n",
        "eval_data['sentence'] = eval_data['sentence'].apply(lambda x: TextBlob(x).correct().raw)"
      ],
      "metadata": {
        "id": "SOXtAAvfhzM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "1jfmaLVelRJc",
        "outputId": "877d27a6-3a69-4ad2-a309-b6fa1009082d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      id                                           sentence  label\n",
              "0  663_3  please enable removing language code from the ...      1\n",
              "1  663_4  note in your csproj file there is a supportedc...      0\n",
              "2  664_1  with means the new version not fully replaced ...      0\n",
              "3  664_2  some of my users will still receive the old ca...      0\n",
              "4  664_3  the store random gives the old cap or the new ...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92f07d39-9778-4466-bfd7-2c0295706a71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>663_3</td>\n",
              "      <td>please enable removing language code from the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>663_4</td>\n",
              "      <td>note in your csproj file there is a supportedc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>664_1</td>\n",
              "      <td>with means the new version not fully replaced ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>664_2</td>\n",
              "      <td>some of my users will still receive the old ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>664_3</td>\n",
              "      <td>the store random gives the old cap or the new ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92f07d39-9778-4466-bfd7-2c0295706a71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92f07d39-9778-4466-bfd7-2c0295706a71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92f07d39-9778-4466-bfd7-2c0295706a71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     id                                           sentence  label\n",
              "0  9566          this would enable live traffic aware apes      0\n",
              "1  9569  please try other forgetting like bold italian ...      1\n",
              "2  9576  since computers were invented to save time i s...      1\n",
              "3  9577  allow rearranging if the user wants to change ...      1\n",
              "4  9579  add sird instructions for better use of arm no...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e0e51f5-adae-4328-b20e-8f6de2557f76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9566</td>\n",
              "      <td>this would enable live traffic aware apes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9569</td>\n",
              "      <td>please try other forgetting like bold italian ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9576</td>\n",
              "      <td>since computers were invented to save time i s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9577</td>\n",
              "      <td>allow rearranging if the user wants to change ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9579</td>\n",
              "      <td>add sird instructions for better use of arm no...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e0e51f5-adae-4328-b20e-8f6de2557f76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e0e51f5-adae-4328-b20e-8f6de2557f76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e0e51f5-adae-4328-b20e-8f6de2557f76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(train_data.head())\n",
        "display(eval_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.to_csv(f'{root_dir}/Data/App_Training_Corrected.csv')\n",
        "eval_data.to_csv(f'{root_dir}/Data/Eval_data_Corrected.csv')\n"
      ],
      "metadata": {
        "id": "HtMpxrBDu3Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKjqW0EiSMUQ"
      },
      "source": [
        "### Model Training 2\n",
        "1. Baseline LSTM model\n",
        "2. Bidirectional LSTM Model\n",
        "3. LSTM with attention\n",
        "4. Impact of adding more layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fXagR_CSLgE"
      },
      "outputs": [],
      "source": [
        "train_df, validate_df = train_test_split(train_data, random_state = 42)\n",
        "X_train,Y_train = train_df['sentence'], train_df['label']\n",
        "X_val, Y_val = validate_df['sentence'], validate_df['label']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU5uJ6ZoP6nJ",
        "outputId": "66406b18-24cc-4895-9a08-594aa6356088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8058"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect = CountVectorizer()\n",
        "vect.fit(X_train)\n",
        "len(vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwtj7NJ0Zkf-"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=8000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "words_to_index = tokenizer.word_index\n",
        "vocab_len = len(words_to_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWcmsBUrSg8e"
      },
      "outputs": [],
      "source": [
        "with open(f'{root_dir}/Data/glove.6B.100d.txt', 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "        w_line = line.split()\n",
        "        curr_word = w_line[0]\n",
        "        word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "MAX_LENGTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHmKD_e3SyAN"
      },
      "outputs": [],
      "source": [
        "vocab_len = len(words_to_index)\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbT1nJ74Q4JR",
        "outputId": "ef0ef871-acaa-40aa-80f2-e62d2e632650"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8086, 100)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFpItsqcTEDl"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape):\n",
        "    X_indices = Input(input_shape)\n",
        "    embeddings = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=150, weights = [emb_matrix], trainable=True)(X_indices)\n",
        "    X = LSTM(128, dropout = 0.3)(embeddings)\n",
        "    X = Dense(1, activation='sigmoid')(X)\n",
        "    model = Model(inputs=X_indices, outputs=X)\n",
        "    return model\n",
        "\n",
        "def create_bilstm_model(input_shape):\n",
        "    X_indices = Input(input_shape)\n",
        "    embeddings = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=150, weights = [emb_matrix], trainable=True)(X_indices)\n",
        "    X = Bidirectional(LSTM(128, dropout = 0.3))(embeddings)\n",
        "    X = Dense(1, activation='sigmoid')(X)\n",
        "    model = Model(inputs=X_indices, outputs=X)\n",
        "    return model\n",
        "\n",
        "def prediction_pipeline(model, X_test, Y_test):\n",
        "    X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "    X_test_indices = pad_sequences(X_test_indices, maxlen=150, padding='pre')\n",
        "    Y_pred = model.predict(X_test_indices) > 0.5\n",
        "    Y_pred = Y_pred.squeeze()\n",
        "    Y_pred = np.array([1 if x else 0 for x in Y_pred ])\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    f1 = f1_score(Y_test, Y_pred)\n",
        "    precision = precision_score(Y_test, Y_pred) \n",
        "    recall = recall_score(Y_test, Y_pred)\n",
        "    return accuracy, f1, precision, recall, Y_pred\n",
        "\n",
        "def prediction_pipeline_attn(model, X_test):\n",
        "    X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "    X_test_indices = pad_sequences(X_test_indices, maxlen=150, padding='pre')\n",
        "    Y_pred = model.predict(X_test_indices)\n",
        "    return X_test_indices, Y_pred\n",
        "\n",
        "def create_bilstm_attn_model_dot(input_shape):\n",
        "    X_indices = Input(input_shape)\n",
        "    embeddings = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=150, weights = [emb_matrix], trainable=True)(X_indices)\n",
        "    lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(128, dropout = 0.3, return_sequences = True, return_state = True))(embeddings)\n",
        "    final_hidden_state = Concatenate()([forward_h, forward_c])\n",
        "    final_hidden_state = tf.expand_dims(final_hidden_state, 2)\n",
        "    mat_matrix = tf.matmul(lstm, final_hidden_state)\n",
        "    attention_weights = tf.nn.softmax(mat_matrix, axis=1)\n",
        "    context_vector = attention_weights * lstm\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    X = Dense(1, activation='sigmoid')(context_vector)\n",
        "    model = Model(inputs=X_indices, outputs=X)  \n",
        "    attn_weights_intermediate = Model(inputs=X_indices, outputs = attention_weights)\n",
        "    return model, attn_weights_intermediate\n",
        "\n",
        "def create_bilstm_attn_model_dot_embeddings(input_shape):\n",
        "    X_indices = Input(input_shape)\n",
        "    embeddings = Embedding(input_dim=vocab_len, output_dim=200, input_length=150, trainable=True)(X_indices)\n",
        "    lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(128, dropout = 0.3, return_sequences = True, return_state = True))(embeddings)\n",
        "    final_hidden_state = Concatenate()([forward_h, forward_c])\n",
        "    final_hidden_state = tf.expand_dims(final_hidden_state, 2)\n",
        "    mat_matrix = tf.matmul(lstm, final_hidden_state)\n",
        "    attention_weights = tf.nn.softmax(mat_matrix, axis=1)\n",
        "    context_vector = attention_weights * lstm\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    X = Dense(1, activation='sigmoid')(context_vector)\n",
        "    model = Model(inputs=X_indices, outputs=X)  \n",
        "    attn_weights_intermediate = Model(inputs=X_indices, outputs = attention_weights)\n",
        "    return model, attn_weights_intermediate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okqrBcalTd8t"
      },
      "outputs": [],
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=150, padding='pre')\n",
        "X_val_indices = tokenizer.texts_to_sequences(X_val)\n",
        "X_val_indices = pad_sequences(X_val_indices, maxlen=150, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFffFZmHT0CE"
      },
      "outputs": [],
      "source": [
        "X_test = eval_data['sentence']\n",
        "Y_test = eval_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hU2HyOqTg_k"
      },
      "outputs": [],
      "source": [
        "model = create_model(150)\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 5, restore_best_weights = True)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=64, epochs=30, callbacks = early_stopping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "CpvIfJcwY1eH",
        "outputId": "bac45162-f854-4628-fa72-1de9597a41bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[713,  33],\n",
              "       [ 29,  58]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9255702280912365\n",
            "Precision: 0.6373626373626373\n",
            "Recall: 0.6666666666666666\n",
            "F1: 0.651685393258427\n"
          ]
        }
      ],
      "source": [
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz8Jcyw9a_iO"
      },
      "outputs": [],
      "source": [
        "model_bidirectionalLSTM = create_bilstm_model(150)\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 5, restore_best_weights = True)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "#Hyperparameters to tune:\n",
        "#Learning rate, batch_size, vocabsize with oov words \n",
        "model_bidirectionalLSTM.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_bidirectionalLSTM.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=64, epochs=40, callbacks = early_stopping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "bnNTQF-jerfj",
        "outputId": "45067dad-1c86-473c-dbc0-547d4bd1d16a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[703,  43],\n",
              "       [ 28,  59]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9147659063625451\n",
            "Precision: 0.5784313725490197\n",
            "Recall: 0.6781609195402298\n",
            "F1: 0.6243386243386243\n"
          ]
        }
      ],
      "source": [
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model_bidirectionalLSTM, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D63Gv3x_f0by"
      },
      "outputs": [],
      "source": [
        "#Attention layer implemented from https://matthewmcateer.me/blog/getting-started-with-attention-for-classification/\n",
        "#This is created using a neural network to simulate, try using dot product instead \n",
        "def create_bilstm_attn_model(input_shape):\n",
        "    X_indices = Input(input_shape)\n",
        "    embeddings = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=150, weights = [emb_matrix], trainable=True)(X_indices)\n",
        "    lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(128, dropout = 0.3, return_sequences = True, return_state = True))(embeddings)\n",
        "    final_hidden_state = Concatenate()([forward_h, forward_c])\n",
        "    final_hidden_state = tf.expand_dims(final_hidden_state, 1)\n",
        "\n",
        "    feature_nn = Dense(10, activation = 'relu')(lstm)\n",
        "    final_hidden_state_nn = Dense(10, activation = 'relu')(final_hidden_state)\n",
        "    score = tf.nn.tanh(feature_nn + final_hidden_state_nn) ## w[x, h]\n",
        "    final_scores = Dense(1)(score)\n",
        "    attention_weights = tf.nn.softmax(final_scores, axis=1, name = 'attn_weights')\n",
        "    context_vector = attention_weights * lstm\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    X = Dense(1, activation='sigmoid')(context_vector)\n",
        "    model = Model(inputs=X_indices, outputs=X)\n",
        "    attn_weights_intermediate = Model(inputs=X_indices, outputs = attention_weights)\n",
        "    return model, attn_weights_intermediate\n",
        "\n",
        "model_bidirectionalLSTM_attn, model_attn_weights_intermediate = create_bilstm_attn_model(150)\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 5, restore_best_weights = True)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "\n",
        "model_bidirectionalLSTM_attn.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_bidirectionalLSTM_attn.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=64, epochs=40, callbacks = early_stopping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "lRmdixe-nqFL",
        "outputId": "bacb11a2-8586-49c1-e5da-f85975e7d22e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[704,  42],\n",
              "       [ 31,  56]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9123649459783914\n",
            "Precision: 0.5714285714285714\n",
            "Recall: 0.6436781609195402\n",
            "F1: 0.6054054054054054\n"
          ]
        }
      ],
      "source": [
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model_bidirectionalLSTM_attn, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2uSy9dG4uR9"
      },
      "outputs": [],
      "source": [
        "model_bidirectionalLSTM_attn, model_attn_weights_intermediate = create_bilstm_attn_model_dot(150)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 4, restore_best_weights = True)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model_bidirectionalLSTM_attn.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_bidirectionalLSTM_attn.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=64, epochs=40, callbacks = early_stopping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "0NhsabMT4_S0",
        "outputId": "27a88415-1b05-46d8-863e-cc2e85a736e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[703,  43],\n",
              "       [ 28,  59]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9147659063625451\n",
            "Precision: 0.5784313725490197\n",
            "Recall: 0.6781609195402298\n",
            "F1: 0.6243386243386243\n"
          ]
        }
      ],
      "source": [
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model_bidirectionalLSTM_attn, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JeLXTauJ5LI"
      },
      "source": [
        "### New Model Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "jn9w9i_YJ-MM",
        "outputId": "f7692237-e412-4545-e249-1ccef4d46d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "214/214 [==============================] - 12s 35ms/step - loss: 0.5776 - accuracy: 0.7324 - val_loss: 0.5110 - val_accuracy: 0.7440\n",
            "Epoch 2/40\n",
            "214/214 [==============================] - 7s 32ms/step - loss: 0.4837 - accuracy: 0.7613 - val_loss: 0.4587 - val_accuracy: 0.7813\n",
            "Epoch 3/40\n",
            "214/214 [==============================] - 4s 19ms/step - loss: 0.4413 - accuracy: 0.7940 - val_loss: 0.4218 - val_accuracy: 0.8099\n",
            "Epoch 4/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.4078 - accuracy: 0.8107 - val_loss: 0.3921 - val_accuracy: 0.8289\n",
            "Epoch 5/40\n",
            "214/214 [==============================] - 5s 24ms/step - loss: 0.3834 - accuracy: 0.8261 - val_loss: 0.3740 - val_accuracy: 0.8381\n",
            "Epoch 6/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.3646 - accuracy: 0.8338 - val_loss: 0.3610 - val_accuracy: 0.8495\n",
            "Epoch 7/40\n",
            "214/214 [==============================] - 4s 18ms/step - loss: 0.3515 - accuracy: 0.8469 - val_loss: 0.3631 - val_accuracy: 0.8429\n",
            "Epoch 8/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.3389 - accuracy: 0.8509 - val_loss: 0.3628 - val_accuracy: 0.8438\n",
            "Epoch 9/40\n",
            "214/214 [==============================] - 5s 23ms/step - loss: 0.3266 - accuracy: 0.8554 - val_loss: 0.3371 - val_accuracy: 0.8636\n",
            "Epoch 10/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.3089 - accuracy: 0.8698 - val_loss: 0.3524 - val_accuracy: 0.8548\n",
            "Epoch 11/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.3065 - accuracy: 0.8686 - val_loss: 0.3333 - val_accuracy: 0.8671\n",
            "Epoch 12/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2911 - accuracy: 0.8745 - val_loss: 0.3408 - val_accuracy: 0.8588\n",
            "Epoch 13/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2819 - accuracy: 0.8784 - val_loss: 0.3382 - val_accuracy: 0.8649\n",
            "Epoch 14/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2727 - accuracy: 0.8828 - val_loss: 0.3297 - val_accuracy: 0.8671\n",
            "Epoch 15/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.3448 - val_accuracy: 0.8491\n",
            "Epoch 16/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2653 - accuracy: 0.8875 - val_loss: 0.3361 - val_accuracy: 0.8575\n",
            "Epoch 17/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2524 - accuracy: 0.8915 - val_loss: 0.3344 - val_accuracy: 0.8685\n",
            "Epoch 18/40\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2470 - accuracy: 0.8956 - val_loss: 0.3314 - val_accuracy: 0.8702\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[701,  45],\n",
              "       [ 25,  62]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9159663865546218\n",
            "Precision: 0.5794392523364486\n",
            "Recall: 0.7126436781609196\n",
            "F1: 0.6391752577319586\n"
          ]
        }
      ],
      "source": [
        "model, model_attn_weights_intermediate = create_bilstm_attn_model_dot(150)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 4, restore_best_weights = True)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=32, epochs=40, callbacks = early_stopping)\n",
        "\n",
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "WnzKtd-5yyq8",
        "outputId": "3d33187a-9176-43f2-c614-1c62fedba6e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "427/427 [==============================] - 11s 19ms/step - loss: 0.5486 - accuracy: 0.7435 - val_loss: 0.4711 - val_accuracy: 0.7730\n",
            "Epoch 2/40\n",
            "427/427 [==============================] - 8s 18ms/step - loss: 0.4563 - accuracy: 0.7872 - val_loss: 0.4177 - val_accuracy: 0.8170\n",
            "Epoch 3/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.3791 - val_accuracy: 0.8385\n",
            "Epoch 4/40\n",
            "427/427 [==============================] - 8s 18ms/step - loss: 0.3770 - accuracy: 0.8321 - val_loss: 0.3599 - val_accuracy: 0.8434\n",
            "Epoch 5/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.3534 - accuracy: 0.8421 - val_loss: 0.3419 - val_accuracy: 0.8539\n",
            "Epoch 6/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.3337 - accuracy: 0.8544 - val_loss: 0.3346 - val_accuracy: 0.8583\n",
            "Epoch 7/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.3175 - accuracy: 0.8657 - val_loss: 0.3322 - val_accuracy: 0.8667\n",
            "Epoch 8/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.3095 - accuracy: 0.8667 - val_loss: 0.3166 - val_accuracy: 0.8685\n",
            "Epoch 9/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.3010 - accuracy: 0.8685 - val_loss: 0.3105 - val_accuracy: 0.8720\n",
            "Epoch 10/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2909 - accuracy: 0.8764 - val_loss: 0.3106 - val_accuracy: 0.8715\n",
            "Epoch 11/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2793 - accuracy: 0.8806 - val_loss: 0.3065 - val_accuracy: 0.8702\n",
            "Epoch 12/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2745 - accuracy: 0.8837 - val_loss: 0.3165 - val_accuracy: 0.8733\n",
            "Epoch 13/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2706 - accuracy: 0.8805 - val_loss: 0.3074 - val_accuracy: 0.8689\n",
            "Epoch 14/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2618 - accuracy: 0.8900 - val_loss: 0.3075 - val_accuracy: 0.8711\n",
            "Epoch 15/40\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2524 - accuracy: 0.8932 - val_loss: 0.3187 - val_accuracy: 0.8742\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[687,  59],\n",
              "       [ 18,  69]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.907563025210084\n",
            "Precision: 0.5390625\n",
            "Recall: 0.7931034482758621\n",
            "F1: 0.641860465116279\n"
          ]
        }
      ],
      "source": [
        "model, model_attn_weights_intermediate = create_bilstm_attn_model_dot(150)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 4, restore_best_weights = True)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=16, epochs=40, callbacks = early_stopping)\n",
        "\n",
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "l5428ntVbsr7",
        "outputId": "d5bc7e9c-4700-4525-ccb7-360f362958dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "427/427 [==============================] - 12s 18ms/step - loss: 0.4538 - accuracy: 0.7894 - val_loss: 0.4408 - val_accuracy: 0.7963\n",
            "Epoch 2/20\n",
            "427/427 [==============================] - 7s 16ms/step - loss: 0.3181 - accuracy: 0.8611 - val_loss: 0.3256 - val_accuracy: 0.8654\n",
            "Epoch 3/20\n",
            "427/427 [==============================] - 7s 16ms/step - loss: 0.2629 - accuracy: 0.8878 - val_loss: 0.2928 - val_accuracy: 0.8843\n",
            "Epoch 4/20\n",
            "427/427 [==============================] - 7s 17ms/step - loss: 0.2127 - accuracy: 0.9081 - val_loss: 0.3070 - val_accuracy: 0.8834\n",
            "Epoch 5/20\n",
            "427/427 [==============================] - 7s 16ms/step - loss: 0.1751 - accuracy: 0.9311 - val_loss: 0.3233 - val_accuracy: 0.8755\n",
            "Epoch 6/20\n",
            "427/427 [==============================] - 7s 16ms/step - loss: 0.1359 - accuracy: 0.9485 - val_loss: 0.3631 - val_accuracy: 0.8724\n",
            "Epoch 7/20\n",
            "427/427 [==============================] - 7s 16ms/step - loss: 0.1101 - accuracy: 0.9579 - val_loss: 0.4201 - val_accuracy: 0.8693\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[717,  29],\n",
              "       [ 23,  64]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9375750300120048\n",
            "Precision: 0.6881720430107527\n",
            "Recall: 0.735632183908046\n",
            "F1: 0.7111111111111111\n"
          ]
        }
      ],
      "source": [
        "#Lets now use BS of 16 with a linear learning rate decay \n",
        "model, model_attn_weights_intermediate = create_bilstm_attn_model_dot(150)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 4, restore_best_weights = True)\n",
        "\n",
        "starter_learning_rate = 0.001\n",
        "end_learning_rate = 0.0000001\n",
        "decay_steps = len(train_df)//16 * 20\n",
        "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    starter_learning_rate,\n",
        "    decay_steps,\n",
        "    end_learning_rate,\n",
        "    power=1)\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=16, epochs=20, callbacks = early_stopping)\n",
        "\n",
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "E0SusQR4VKeg",
        "outputId": "b0a2c2f9-31fb-4ef6-c563-4a5eb3d15471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "214/214 [==============================] - 9s 23ms/step - loss: 0.4839 - accuracy: 0.7706 - val_loss: 0.4480 - val_accuracy: 0.7444\n",
            "Epoch 2/20\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.3593 - accuracy: 0.8431 - val_loss: 0.3523 - val_accuracy: 0.8548\n",
            "Epoch 3/20\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.3046 - accuracy: 0.8708 - val_loss: 0.3174 - val_accuracy: 0.8680\n",
            "Epoch 4/20\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2509 - accuracy: 0.8934 - val_loss: 0.3209 - val_accuracy: 0.8689\n",
            "Epoch 5/20\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.2248 - accuracy: 0.9100 - val_loss: 0.3242 - val_accuracy: 0.8720\n",
            "Epoch 6/20\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.1882 - accuracy: 0.9229 - val_loss: 0.3241 - val_accuracy: 0.8755\n",
            "Epoch 7/20\n",
            "214/214 [==============================] - 4s 17ms/step - loss: 0.1530 - accuracy: 0.9388 - val_loss: 0.3864 - val_accuracy: 0.8711\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[718,  28],\n",
              "       [ 29,  58]])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9315726290516206\n",
            "Precision: 0.6744186046511628\n",
            "Recall: 0.6666666666666666\n",
            "F1: 0.6705202312138728\n"
          ]
        }
      ],
      "source": [
        "#Lets now use BS of 16 with a linear learning rate decay \n",
        "model, model_attn_weights_intermediate = create_bilstm_attn_model_dot(150)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 4, restore_best_weights = True)\n",
        "\n",
        "starter_learning_rate = 0.001\n",
        "end_learning_rate = 0.0000001\n",
        "decay_steps = len(train_df)//32 * 20\n",
        "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    starter_learning_rate,\n",
        "    decay_steps,\n",
        "    end_learning_rate,\n",
        "    power=1)\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=32, epochs=20, callbacks = early_stopping)\n",
        "\n",
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets now use BS of 16 with a linear learning rate decay \n",
        "model, model_attn_weights_intermediate = create_bilstm_attn_model_dot_embeddings(150)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor ='val_loss', patience = 4, restore_best_weights = True)\n",
        "\n",
        "starter_learning_rate = 0.001\n",
        "end_learning_rate = 0.0000001\n",
        "decay_steps = len(train_df)//16 * 20\n",
        "learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    starter_learning_rate,\n",
        "    decay_steps,\n",
        "    end_learning_rate,\n",
        "    power=1)\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate = learning_rate_fn)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_indices, Y_train, validation_data = (X_val_indices, Y_val), batch_size=16, epochs=20, callbacks = early_stopping)\n",
        "\n",
        "accuracy, f1, precision, recall, Y_pred = prediction_pipeline(model, X_test, Y_test)\n",
        "display(confusion_matrix(Y_test, Y_pred))\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "v6a-jsgze3ZB",
        "outputId": "eeaee18b-92fb-4647-84dc-5a1b93d63c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "427/427 [==============================] - 15s 23ms/step - loss: 0.4283 - accuracy: 0.8161 - val_loss: 0.3568 - val_accuracy: 0.8557\n",
            "Epoch 2/20\n",
            "427/427 [==============================] - 8s 20ms/step - loss: 0.2716 - accuracy: 0.8918 - val_loss: 0.3399 - val_accuracy: 0.8636\n",
            "Epoch 3/20\n",
            "427/427 [==============================] - 8s 20ms/step - loss: 0.1795 - accuracy: 0.9290 - val_loss: 0.3784 - val_accuracy: 0.8557\n",
            "Epoch 4/20\n",
            "427/427 [==============================] - 9s 21ms/step - loss: 0.1131 - accuracy: 0.9547 - val_loss: 0.5510 - val_accuracy: 0.8214\n",
            "Epoch 5/20\n",
            "427/427 [==============================] - 8s 20ms/step - loss: 0.0884 - accuracy: 0.9666 - val_loss: 0.5825 - val_accuracy: 0.8460\n",
            "Epoch 6/20\n",
            "427/427 [==============================] - 8s 20ms/step - loss: 0.0638 - accuracy: 0.9761 - val_loss: 0.5728 - val_accuracy: 0.8377\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[704,  42],\n",
              "       [ 27,  60]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9171668667466987\n",
            "Precision: 0.5882352941176471\n",
            "Recall: 0.6896551724137931\n",
            "F1: 0.6349206349206349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTxW6xb1AGfy"
      },
      "source": [
        "### Extract out attention weights from the text and key features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2Srewiy69ka"
      },
      "outputs": [],
      "source": [
        "X_series, attn_weights = prediction_pipeline_attn(model_attn_weights_intermediate, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQmcsxMBBin6"
      },
      "outputs": [],
      "source": [
        "def highlight_attn_weights(X_series, attn_weights, tokenizer):\n",
        "    #Given a set of attention weights, return the top 5 tokens per word and decode them\n",
        "    #Returns a list of text that aligns with X_series \n",
        "    attn_weights = attn_weights.squeeze()\n",
        "    top_5_indexes = attn_weights.argsort(axis = 1)[:, -1:-6:-1]\n",
        "    top_5_tokens_arr = []\n",
        "    for i in range(len(X_series)):\n",
        "        top_5_words = X_series[i][top_5_indexes[0]]\n",
        "        top_5_tokens_arr.append(top_5_words)\n",
        "    top_5_tokens_arr = np.array(top_5_tokens_arr)\n",
        "    return tokenizer.sequences_to_texts(top_5_tokens_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Ev5aCb3L_N1o",
        "outputId": "6f006a6a-4c3e-4f6f-ce30-887e9e9351a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4721e6e-fc93-4332-99b8-227f9c200fa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>top_5_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9566</td>\n",
              "      <td>this would enable live traffic aware apps</td>\n",
              "      <td>0</td>\n",
              "      <td>live aware traffic apps enable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9569</td>\n",
              "      <td>please try other formatting like bold italics ...</td>\n",
              "      <td>1</td>\n",
              "      <td>shadow from to content like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9576</td>\n",
              "      <td>since computers were invented to save time i s...</td>\n",
              "      <td>1</td>\n",
              "      <td>in right the order them</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9577</td>\n",
              "      <td>allow rearranging if the user wants to change ...</td>\n",
              "      <td>1</td>\n",
              "      <td>wants change to them user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9579</td>\n",
              "      <td>add simd instructions for better use of arm ne...</td>\n",
              "      <td>1</td>\n",
              "      <td>instructions and for games arm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>6340</td>\n",
              "      <td>it could be something like</td>\n",
              "      <td>0</td>\n",
              "      <td>could something be like it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>6341</td>\n",
              "      <td>for input nodes</td>\n",
              "      <td>0</td>\n",
              "      <td>input for nodes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>6351</td>\n",
              "      <td>it would be very very appreciated</td>\n",
              "      <td>0</td>\n",
              "      <td>be very very appreciated would</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>831</th>\n",
              "      <td>6357</td>\n",
              "      <td>i have made an app when i search for it 10 app...</td>\n",
              "      <td>0</td>\n",
              "      <td>app of any them my</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>6358</td>\n",
              "      <td>i just chatted to support they told me that it...</td>\n",
              "      <td>0</td>\n",
              "      <td>name too was generic the</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>833 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4721e6e-fc93-4332-99b8-227f9c200fa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4721e6e-fc93-4332-99b8-227f9c200fa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4721e6e-fc93-4332-99b8-227f9c200fa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       id                                           sentence  label  \\\n",
              "0    9566          this would enable live traffic aware apps      0   \n",
              "1    9569  please try other formatting like bold italics ...      1   \n",
              "2    9576  since computers were invented to save time i s...      1   \n",
              "3    9577  allow rearranging if the user wants to change ...      1   \n",
              "4    9579  add simd instructions for better use of arm ne...      1   \n",
              "..    ...                                                ...    ...   \n",
              "828  6340                         it could be something like      0   \n",
              "829  6341                                    for input nodes      0   \n",
              "830  6351                  it would be very very appreciated      0   \n",
              "831  6357  i have made an app when i search for it 10 app...      0   \n",
              "832  6358  i just chatted to support they told me that it...      0   \n",
              "\n",
              "                       top_5_tokens  \n",
              "0    live aware traffic apps enable  \n",
              "1       shadow from to content like  \n",
              "2           in right the order them  \n",
              "3         wants change to them user  \n",
              "4    instructions and for games arm  \n",
              "..                              ...  \n",
              "828      could something be like it  \n",
              "829                 input for nodes  \n",
              "830  be very very appreciated would  \n",
              "831              app of any them my  \n",
              "832        name too was generic the  \n",
              "\n",
              "[833 rows x 4 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_data['top_5_tokens'] = highlight_attn_weights(X_series, attn_weights, tokenizer)\n",
        "eval_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAhCMTj1BKjF",
        "outputId": "4371dba1-d552-4d31-e535-e8d887858e9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "the        27\n",
              "to         23\n",
              "in         12\n",
              "for        12\n",
              "and        11\n",
              "app         8\n",
              "it          7\n",
              "is          6\n",
              "like        5\n",
              "of          5\n",
              "by          4\n",
              "one         4\n",
              "windows     4\n",
              "be          4\n",
              "camera      3\n",
              "from        3\n",
              "data        3\n",
              "user        3\n",
              "just        3\n",
              "should      3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_eval_data = eval_data[eval_data['label'] == 1]\n",
        "vectorizer = CountVectorizer()\n",
        "count_vectors = vectorizer.fit_transform(pos_eval_data['top_5_tokens'])\n",
        "pd.DataFrame(count_vectors.toarray(), columns = vectorizer.get_feature_names_out()).sum(axis = 0).sort_values(ascending = False)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvZ-JoSaaA1w"
      },
      "source": [
        "### Model Training with BERT based models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuOG9pgi6p1U"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "class BertForClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForClassification, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        X = self.bert(input_ids, attention_mask, return_dict=False)[1]\n",
        "        X = self.dropout(X)\n",
        "        X = self.classifier(X)\n",
        "        return X\n",
        "\n",
        "    def extract_attn_weights(self, input_ids, attention_mask):\n",
        "        attentions = self.bert(input_ids, attention_mask, output_attentions = True)['attentions ']\n",
        "        return attentions\n",
        "\n",
        "class BertDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.labels = torch.tensor(df['label'].tolist(), dtype = torch.float64)\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 256, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['sentence']]\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8glTD-rCWDh"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, loss_fn, optimizer, scheduler, model, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        input_ids = X['input_ids'].squeeze(1).to(device)\n",
        "        attn_mask = X['attention_mask'].to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(input_ids, attn_mask).squeeze()\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def eval_loop(dataloader, loss_fn, model, device):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            input_ids = X['input_ids'].squeeze(1).to(device)\n",
        "            attn_mask = X['attention_mask'].to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(input_ids, attn_mask).squeeze()\n",
        "            try:\n",
        "                test_loss += loss_fn(pred, y).item()\n",
        "            except:\n",
        "                print(pred)\n",
        "                print(input_ids, attn_mask, y)\n",
        "                raise ValueError(\"Error\")\n",
        "            correct += (pred == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "def generate_train_val_dataloaders(train_df, validation_df, tokenizer):\n",
        "    train_dataset = BertDataset(train_df, tokenizer)\n",
        "    validation_dataset = BertDataset(validation_df, tokenizer)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last = True)\n",
        "    validation_dataloader = DataLoader(validation_dataset, batch_size = 16, shuffle = True, drop_last = True)\n",
        "    return train_dataloader, validation_dataloader\n",
        "\n",
        "def full_train_cycle(num_epochs, train_df, validation_df, device, tokenizer):\n",
        "    model = BertForClassification()\n",
        "    model.to(device)\n",
        "    train_dataloader, test_dataloader = generate_train_val_dataloaders(train_df, validation_df, tokenizer)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-5, steps_per_epoch=len(train_dataloader), epochs=num_epochs, pct_start = 0.1, anneal_strategy  = 'linear')\n",
        "    for t in range(num_epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(train_dataloader, loss_fn, optimizer, scheduler, model, device)\n",
        "        eval_loop(test_dataloader, loss_fn, model, device)\n",
        "    return model \n",
        "\n",
        "def make_prediction(test_df, model, tokenizer):\n",
        "    model.eval()\n",
        "    model.to('cpu')\n",
        "    sentence_idx = test_df.columns.get_loc('sentence') + 1 \n",
        "    res = []\n",
        "    for row in test_df.itertuples():\n",
        "        sentence = row[sentence_idx]\n",
        "        tokenized = tokenizer(sentence, padding='max_length', max_length = 256, truncation=True, return_tensors=\"pt\")\n",
        "        pred = model(tokenized['input_ids'], tokenized['attention_mask']).squeeze()\n",
        "        pred = torch.nn.functional.sigmoid(pred).item() \n",
        "        res.append(pred)\n",
        "    sigmoid_res = [1 if logit >= 0.5 else 0 for logit in res]\n",
        "    return sigmoid_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQX6rWlmFbO-"
      },
      "outputs": [],
      "source": [
        "train_df, validation_df = train_test_split(train_data, random_state = 42)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model = full_train_cycle(3, train_df, validation_df, device, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuMpYRrcgBWd"
      },
      "outputs": [],
      "source": [
        "trained_model = BertForClassification()\n",
        "trained_model.load_state_dict(torch.load(f\"{root_dir}/Data/BertWeights.pt\"))\n",
        "trained_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wWjD4Czehmi",
        "outputId": "7e6b46a6-dd52-4963-e916-ab11141a506a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7567567567567568\n",
            "Recall Score: 0.8045977011494253\n",
            "Precision Score: 0.7142857142857143\n",
            "Accuracy Score: 0.9459783913565426\n"
          ]
        }
      ],
      "source": [
        "preds = make_prediction(eval_data, trained_model, tokenizer)\n",
        "labels = eval_data['label'].tolist()\n",
        "confusion_matrix(labels, preds)\n",
        "print(f\"F1 Score: {f1_score(labels, preds)}\")\n",
        "print(f\"Recall Score: {recall_score(labels, preds)}\")\n",
        "print(f\"Precision Score: {precision_score(labels, preds)}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(labels, preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New set of improvements for BERT models: \n",
        "1. BERT With more dense layers before classification\n",
        "2. BERT with LSTM "
      ],
      "metadata": {
        "id": "i1c6miRZ_wMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForClassificationMultiple(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForClassificationMultiple, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.l1 = nn.Linear(768, 512)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.l2 = nn.Linear(512, 256)\n",
        "        self.classifier = nn.Linear(256, 1)\n",
        "         \n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        X = self.bert(input_ids, attention_mask, return_dict=False)[1]\n",
        "        X = self.dropout(X)\n",
        "        X = self.l1(X)\n",
        "        X = self.dropout2(X)\n",
        "        X = self.l2(X)\n",
        "        X = self.classifier(X)\n",
        "        return X\n",
        "\n",
        "    def extract_attn_weights(self, input_ids, attention_mask):\n",
        "        attentions = self.bert(input_ids, attention_mask, output_attentions = True)['attentions ']\n",
        "        return attentions\n",
        "\n",
        "def full_train_cycle_multiple(num_epochs, train_df, validation_df, device, tokenizer):\n",
        "    model = BertForClassificationMultiple()\n",
        "    model.to(device)\n",
        "    train_dataloader, test_dataloader = generate_train_val_dataloaders(train_df, validation_df, tokenizer)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-5, steps_per_epoch=len(train_dataloader), epochs=num_epochs, pct_start = 0.1, anneal_strategy  = 'linear')\n",
        "    for t in range(num_epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(train_dataloader, loss_fn, optimizer, scheduler, model, device)\n",
        "        eval_loop(test_dataloader, loss_fn, model, device)\n",
        "    return model "
      ],
      "metadata": {
        "id": "z8AhqOCSABw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validation_df = train_test_split(train_data, random_state = 42)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model = full_train_cycle_multiple(3, train_df, validation_df, device, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WRzr1LJBGLd",
        "outputId": "25115abe-4f97-405a-9511-4182a8f60858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.691674  [    0/ 6819]\n",
            "loss: 0.416721  [  300/ 6819]\n",
            "loss: 0.252449  [  600/ 6819]\n",
            "loss: 0.181144  [  900/ 6819]\n",
            "loss: 0.260524  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.238401 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.129126  [    0/ 6819]\n",
            "loss: 0.252260  [  300/ 6819]\n",
            "loss: 0.196877  [  600/ 6819]\n",
            "loss: 0.552070  [  900/ 6819]\n",
            "loss: 0.032336  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.244936 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.155832  [    0/ 6819]\n",
            "loss: 0.019675  [  300/ 6819]\n",
            "loss: 0.011135  [  600/ 6819]\n",
            "loss: 0.213412  [  900/ 6819]\n",
            "loss: 0.017594  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.278703 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trained_model.state_dict(), f\"{root_dir}/Data/BertWeightsMultipleDenseLayers.pt\")"
      ],
      "metadata": {
        "id": "EXQdFCfsP5zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = make_prediction(eval_data, trained_model, tokenizer)\n",
        "labels = eval_data['label'].tolist()\n",
        "print(f\"F1 Score: {f1_score(labels, preds)}\")\n",
        "print(f\"Recall Score: {recall_score(labels, preds)}\")\n",
        "print(f\"Precision Score: {precision_score(labels, preds)}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(labels, preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kuEcgnBCWa1",
        "outputId": "4ef10e98-dd8a-41c3-c452-548cc9e02ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.7582417582417583\n",
            "Recall Score: 0.7931034482758621\n",
            "Precision Score: 0.7263157894736842\n",
            "Accuracy Score: 0.9471788715486195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(labels, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HrpOuxJPz7V",
        "outputId": "19b1c3cc-a63b-43f7-da04-0fded646fbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[720,  26],\n",
              "       [ 18,  69]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validation_df = train_test_split(train_data, random_state = 42)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model = full_train_cycle_multiple(3, train_df, validation_df, device, tokenizer)\n",
        "\n",
        "preds = make_prediction(eval_data, trained_model, tokenizer)\n",
        "labels = eval_data['label'].tolist()\n",
        "print(f\"F1 Score: {f1_score(labels, preds)}\")\n",
        "print(f\"Recall Score: {recall_score(labels, preds)}\")\n",
        "print(f\"Precision Score: {precision_score(labels, preds)}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(labels, preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDbnEhqa7Xsp",
        "outputId": "2dfb959b-c98e-4559-d072-dcf9176facb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.733559  [    0/ 6819]\n",
            "loss: 0.597525  [  300/ 6819]\n",
            "loss: 0.243157  [  600/ 6819]\n",
            "loss: 0.229948  [  900/ 6819]\n",
            "loss: 0.258119  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.237608 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.166411  [    0/ 6819]\n",
            "loss: 0.351938  [  300/ 6819]\n",
            "loss: 0.116235  [  600/ 6819]\n",
            "loss: 0.110033  [  900/ 6819]\n",
            "loss: 0.247821  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.236538 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.078914  [    0/ 6819]\n",
            "loss: 0.009478  [  300/ 6819]\n",
            "loss: 0.107530  [  600/ 6819]\n",
            "loss: 0.065381  [  900/ 6819]\n",
            "loss: 0.011523  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.263963 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.7301587301587301\n",
            "Recall Score: 0.7931034482758621\n",
            "Precision Score: 0.6764705882352942\n",
            "Accuracy Score: 0.9387755102040817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForClassificationLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForClassificationLSTM, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.LSTM = nn.LSTM(input_size = 768, hidden_size = 256, batch_first = True)\n",
        "        self.classifier = nn.Linear(256, 1)\n",
        "         \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        X = self.bert(input_ids, attention_mask, return_dict=False)[0]\n",
        "        X = self.dropout(X)\n",
        "        X, _ = self.LSTM(X)\n",
        "        X = self.classifier(X[:,-1,:])\n",
        "        return X\n",
        "\n",
        "    def extract_attn_weights(self, input_ids, attention_mask):\n",
        "        attentions = self.bert(input_ids, attention_mask, output_attentions = True)['attentions ']\n",
        "        return attentions\n",
        "\n",
        "def full_train_cycle_BERTLstm(num_epochs, train_df, validation_df, device, tokenizer):\n",
        "    model = BertForClassificationLSTM()\n",
        "    model.to(device)\n",
        "    train_dataloader, test_dataloader = generate_train_val_dataloaders(train_df, validation_df, tokenizer)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-5, steps_per_epoch=len(train_dataloader), epochs=num_epochs, pct_start = 0.1, anneal_strategy  = 'linear')\n",
        "    for t in range(num_epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(train_dataloader, loss_fn, optimizer, scheduler, model, device)\n",
        "        eval_loop(test_dataloader, loss_fn, model, device)\n",
        "    return model "
      ],
      "metadata": {
        "id": "zBhwcqjfGy5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validation_df = train_test_split(train_data, random_state = 42)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model = full_train_cycle_BERTLstm(2, train_df, validation_df, device, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psjES9xRQGqQ",
        "outputId": "e5cc2e50-9026-4036-ac90-8dbe93780243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.709174  [    0/ 6819]\n",
            "loss: 0.336621  [  300/ 6819]\n",
            "loss: 0.345218  [  600/ 6819]\n",
            "loss: 0.471101  [  900/ 6819]\n",
            "loss: 0.447193  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.237060 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.185294  [    0/ 6819]\n",
            "loss: 0.114724  [  300/ 6819]\n",
            "loss: 0.145153  [  600/ 6819]\n",
            "loss: 0.280575  [  900/ 6819]\n",
            "loss: 0.030968  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.230080 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = make_prediction(eval_data, trained_model, tokenizer)\n",
        "labels = eval_data['label'].tolist()\n",
        "display(confusion_matrix(labels, preds))\n",
        "print(f\"F1 Score: {f1_score(labels, preds)}\")\n",
        "print(f\"Recall Score: {recall_score(labels, preds)}\")\n",
        "print(f\"Precision Score: {precision_score(labels, preds)}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(labels, preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "XCuCGbStQJqQ",
        "outputId": "3cd3d8e5-c582-4570-bbb4-7de6535e9523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[715,  31],\n",
              "       [ 17,  70]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.7446808510638299\n",
            "Recall Score: 0.8045977011494253\n",
            "Precision Score: 0.693069306930693\n",
            "Accuracy Score: 0.9423769507803121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trained_model.state_dict(), f\"{root_dir}/Data/BertWithLSTM.pt\")"
      ],
      "metadata": {
        "id": "feRF4EBLVYBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForClassificationBiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertForClassificationBiLSTM, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.LSTM = nn.LSTM(input_size = 768, hidden_size = 256, batch_first = True, bidirectional = True)\n",
        "        self.classifier = nn.Linear(512, 1)\n",
        "         \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        X = self.bert(input_ids, attention_mask, return_dict=False)[0]\n",
        "        X = self.dropout(X)\n",
        "        X, _ = self.LSTM(X)\n",
        "        X = self.classifier(X[:,-1,:])\n",
        "        return X\n",
        "\n",
        "    def extract_attn_weights(self, input_ids, attention_mask):\n",
        "        attentions = self.bert(input_ids, attention_mask, output_attentions = True)['attentions ']\n",
        "        return attentions\n",
        "\n",
        "def full_train_cycle_BERTBiLstm(num_epochs, train_df, validation_df, device, tokenizer):\n",
        "    model = BertForClassificationBiLSTM()\n",
        "    model.to(device)\n",
        "    train_dataloader, test_dataloader = generate_train_val_dataloaders(train_df, validation_df, tokenizer)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=2e-5, steps_per_epoch=len(train_dataloader), epochs=num_epochs, pct_start = 0.1, anneal_strategy  = 'linear')\n",
        "    for t in range(num_epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        train_loop(train_dataloader, loss_fn, optimizer, scheduler, model, device)\n",
        "        eval_loop(test_dataloader, loss_fn, model, device)\n",
        "    return model "
      ],
      "metadata": {
        "id": "lnydYwnGWLtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validation_df = train_test_split(train_data, random_state = 42)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_model = full_train_cycle_BERTBiLstm(2, train_df, validation_df, device, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RSTjhtrWVOC",
        "outputId": "7b0d3099-3eb4-44a6-b965-0bd6d042cb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.684836  [    0/ 6819]\n",
            "loss: 0.479770  [  300/ 6819]\n",
            "loss: 0.346597  [  600/ 6819]\n",
            "loss: 0.236227  [  900/ 6819]\n",
            "loss: 0.188925  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.235080 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.118277  [    0/ 6819]\n",
            "loss: 0.067105  [  300/ 6819]\n",
            "loss: 0.067803  [  600/ 6819]\n",
            "loss: 0.043720  [  900/ 6819]\n",
            "loss: 0.438511  [ 1200/ 6819]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 0.236919 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = make_prediction(eval_data, trained_model, tokenizer)\n",
        "labels = eval_data['label'].tolist()\n",
        "display(confusion_matrix(labels, preds))\n",
        "print(f\"F1 Score: {f1_score(labels, preds)}\")\n",
        "print(f\"Recall Score: {recall_score(labels, preds)}\")\n",
        "print(f\"Precision Score: {precision_score(labels, preds)}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(labels, preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "_Q7kXaYTWVQf",
        "outputId": "c939ec70-5589-4025-8de8-962b68c45537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[717,  29],\n",
              "       [ 17,  70]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.7526881720430108\n",
            "Recall Score: 0.8045977011494253\n",
            "Precision Score: 0.7070707070707071\n",
            "Accuracy Score: 0.9447779111644657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trained_model.state_dict(), f\"{root_dir}/Data/BertWithBiLSTM.pt\")"
      ],
      "metadata": {
        "id": "ZHxJBF7dWYcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G3OqvcoI3X7"
      },
      "source": [
        "### Extracting attention weights from the BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQdQCxR6I6ZP"
      },
      "outputs": [],
      "source": [
        "#Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
        "\n",
        "def get_attention_weights(model, text, tokenizer):\n",
        "    model.eval()\n",
        "    tokenized = tokenizer(text, padding='max_length', max_length = 256, truncation=True, return_tensors=\"pt\")\n",
        "    input_ids, attention_mask = tokenized['input_ids'], tokenized['attention_mask']\n",
        "    attentions = model.bert(input_ids, attention_mask, output_attentions = True)\n",
        "    return attentions\n",
        "\n",
        "a = get_attention_weights(trained_model, eval_data['sentence'][0], tokenizer)['attentions']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nxIqsjJ8k1vd",
        "kKjqW0EiSMUQ",
        "7JeLXTauJ5LI",
        "ZTxW6xb1AGfy"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}